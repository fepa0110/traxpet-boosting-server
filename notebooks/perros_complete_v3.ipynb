{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas\n",
    "from catboost import CatBoostClassifier, Pool, metrics, cv\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def load_data():\n",
    "train_df = pandas.read_csv('../data/perros_train_v3.csv')\n",
    "train_df\n",
    "\n",
    "test_df = pandas.read_csv('../data/perros_predict_v3.csv')\n",
    "# test_df.head()\n",
    "\n",
    "# load_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train_df.Mascota\n",
    "X = train_df.drop('Mascota', axis=1)\n",
    "\n",
    "X.fillna(\"NaN\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n"
     ]
    }
   ],
   "source": [
    "cat_features = list(range(0, X.shape[1]))\n",
    "print(cat_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels: {1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 4191, 4194, 4210, 4229, 4230, 4235, 4240, 4243, 4102, 4272, 4274, 4107, 4282, 4299, 4303, 4307, 4338, 4340, 4341, 4350, 4352, 4353, 4354, 4385, 4390, 4391, 4393, 4397, 4400, 4401, 4404, 4407, 4411, 4413, 4416, 4427, 4434, 4436, 4437, 4464, 4465, 4466, 4467, 4468, 4473, 4478, 4480, 4491, 4492, 4502, 4512, 4515, 4516, 4531, 4535, 4537, 4539, 4541, 4546, 4547, 4551, 4642, 1000, 1002, 1003, 1007, 1009, 1010, 1014, 1018, 1036, 1048, 1053, 1066, 1067, 1074, 1081, 1082, 1083, 1095, 1100, 1116, 1121, 1122, 1129, 1136, 1144, 1157, 1166, 1174, 1183, 1186, 1191, 1207, 1215, 1217, 1219, 1223, 1224, 1227, 1232, 1235, 1238, 1279, 1329, 1343, 1360, 1372, 1373, 1377, 1381, 1382, 1385, 1387, 1395, 1399, 1401, 1409, 1431, 1432, 1434, 3485, 1444, 3500, 1452, 3505, 3507, 1460, 3512, 1468, 1470, 3524, 1476, 1477, 3528, 3530, 1486, 1495, 1498, 1508, 1509, 1516, 1525, 1526, 1529, 1531, 3592, 1546, 3595, 1549, 3601, 1564, 3631, 1593, 1596, 1640, 1652, 3701, 1682, 1693, 1701, 1702, 3752, 1706, 1722, 1730, 3780, 1732, 1737, 3788, 3789, 3793, 3809, 1761, 1766, 1767, 1776, 1782, 1789, 3848, 1800, 1801, 1807, 1821, 1837, 1838, 1849, 1851, 3907, 3910, 1863, 3913, 3914, 3917, 1872, 1874, 3923, 3931, 1884, 3933, 1886, 3950, 1902, 6000, 1906, 6004, 1908, 1910, 6007, 3961, 6010, 6012, 1919, 6016, 6017, 6019, 6020, 6022, 6025, 6026, 6027, 6028, 6030, 1940, 6038, 6040, 6041, 6042, 6045, 6046, 6047, 1950, 6049, 1954, 6051, 6055, 6064, 6065, 6066, 6067, 6070, 6072, 6073, 4026, 6075, 6078, 6079, 4053, 4073, 4077}\n",
      "Zero count = -787182, One count = 787502\n"
     ]
    }
   ],
   "source": [
    "print('Labels: {}'.format(set(y)))\n",
    "print('Zero count = {}, One count = {}'.format(len(y) - sum(y), sum(y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape\n",
      "dataset 3:(320, 13)\n",
      "\n",
      "\n",
      "Column names\n",
      "\n",
      "dataset 3:\n",
      "['Edad', 'Tama√±o', 'Sexo', 'Patron de pelaje', 'Color de pelaje 1', 'Color de pelaje 2', 'Color de pelaje 3', 'Largo de pelaje', 'Color de ojos', 'Largo de hocico', 'Largo de cola', 'Largo de orejas', 'Tipo de orejas']\n"
     ]
    }
   ],
   "source": [
    "pool3 = Pool(data=X, cat_features=cat_features)\n",
    "\n",
    "print('Dataset shape')\n",
    "print('dataset 3:' + str(pool3.shape))\n",
    "\n",
    "print('\\n')\n",
    "print('Column names')\n",
    "print('\\ndataset 3:')\n",
    "print(pool3.get_feature_names())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_validation, y_train, y_validation = train_test_split(\n",
    "    X, y, train_size=0.8, random_state=1234)\n",
    "\n",
    "\n",
    "validation_df = pandas.read_csv('../data/perros_validation_v3.csv')\n",
    "y_validation = train_df.Mascota\n",
    "X_validation = train_df.drop('Mascota', axis=1)\n",
    "X_validation.fillna(\"NaN\", inplace=True)\n",
    "\n",
    "X_train = X\n",
    "y_train = y\n",
    "# X_validation = \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.217853\n",
      "0:\tlearn: 5.7264805\ttest: 5.7489845\tbest: 5.7489845 (0)\ttotal: 12.6s\tremaining: 31m 12s\n",
      "1:\tlearn: 5.7208214\ttest: 5.7490804\tbest: 5.7489845 (0)\ttotal: 22.1s\tremaining: 27m 15s\n",
      "2:\tlearn: 5.6800941\ttest: 5.7247172\tbest: 5.7247172 (2)\ttotal: 32.4s\tremaining: 26m 29s\n",
      "3:\tlearn: 5.6225687\ttest: 5.7005180\tbest: 5.7005180 (3)\ttotal: 42.4s\tremaining: 25m 49s\n",
      "4:\tlearn: 5.5837559\ttest: 5.6893166\tbest: 5.6893166 (4)\ttotal: 53s\tremaining: 25m 36s\n",
      "5:\tlearn: 5.5561626\ttest: 5.6831000\tbest: 5.6831000 (5)\ttotal: 1m 2s\tremaining: 25m 11s\n",
      "6:\tlearn: 5.5539402\ttest: 5.6831497\tbest: 5.6831000 (5)\ttotal: 1m 12s\tremaining: 24m 44s\n",
      "7:\tlearn: 5.5123570\ttest: 5.6576634\tbest: 5.6576634 (7)\ttotal: 1m 22s\tremaining: 24m 19s\n",
      "8:\tlearn: 5.4654654\ttest: 5.6148189\tbest: 5.6148189 (8)\ttotal: 1m 31s\tremaining: 24m\n",
      "9:\tlearn: 5.4581292\ttest: 5.6151007\tbest: 5.6148189 (8)\ttotal: 1m 37s\tremaining: 22m 38s\n",
      "10:\tlearn: 5.4319517\ttest: 5.6020438\tbest: 5.6020438 (10)\ttotal: 1m 46s\tremaining: 22m 27s\n",
      "11:\tlearn: 5.3939238\ttest: 5.5793417\tbest: 5.5793417 (11)\ttotal: 1m 56s\tremaining: 22m 16s\n",
      "12:\tlearn: 5.3881619\ttest: 5.5795693\tbest: 5.5793417 (11)\ttotal: 2m 5s\tremaining: 22m 6s\n",
      "13:\tlearn: 5.3464224\ttest: 5.5586507\tbest: 5.5586507 (13)\ttotal: 2m 15s\tremaining: 21m 55s\n",
      "14:\tlearn: 5.2987058\ttest: 5.5528363\tbest: 5.5528363 (14)\ttotal: 2m 23s\tremaining: 21m 29s\n",
      "15:\tlearn: 5.2517637\ttest: 5.5325887\tbest: 5.5325887 (15)\ttotal: 2m 33s\tremaining: 21m 21s\n",
      "16:\tlearn: 5.2083201\ttest: 5.4982826\tbest: 5.4982826 (16)\ttotal: 2m 42s\tremaining: 21m 14s\n",
      "17:\tlearn: 5.1715163\ttest: 5.4765853\tbest: 5.4765853 (17)\ttotal: 2m 53s\tremaining: 21m 9s\n",
      "18:\tlearn: 5.1261599\ttest: 5.4603200\tbest: 5.4603200 (18)\ttotal: 3m 2s\tremaining: 21m\n",
      "19:\tlearn: 5.0950128\ttest: 5.4435487\tbest: 5.4435487 (19)\ttotal: 3m 12s\tremaining: 20m 53s\n",
      "20:\tlearn: 5.0515393\ttest: 5.4357002\tbest: 5.4357002 (20)\ttotal: 3m 22s\tremaining: 20m 44s\n",
      "21:\tlearn: 5.0136310\ttest: 5.4301803\tbest: 5.4301803 (21)\ttotal: 3m 32s\tremaining: 20m 34s\n",
      "22:\tlearn: 4.9916247\ttest: 5.4301291\tbest: 5.4301291 (22)\ttotal: 3m 42s\tremaining: 20m 26s\n",
      "23:\tlearn: 4.9531164\ttest: 5.4198610\tbest: 5.4198610 (23)\ttotal: 3m 52s\tremaining: 20m 19s\n",
      "24:\tlearn: 4.9195746\ttest: 5.3982282\tbest: 5.3982282 (24)\ttotal: 4m 2s\tremaining: 20m 10s\n",
      "25:\tlearn: 4.8757815\ttest: 5.3930880\tbest: 5.3930880 (25)\ttotal: 4m 12s\tremaining: 20m 2s\n",
      "26:\tlearn: 4.8413300\ttest: 5.3793750\tbest: 5.3793750 (26)\ttotal: 4m 21s\tremaining: 19m 53s\n",
      "27:\tlearn: 4.8353673\ttest: 5.3796877\tbest: 5.3793750 (26)\ttotal: 4m 31s\tremaining: 19m 44s\n",
      "28:\tlearn: 4.7911262\ttest: 5.3596176\tbest: 5.3596176 (28)\ttotal: 4m 42s\tremaining: 19m 37s\n",
      "29:\tlearn: 4.7686516\ttest: 5.3609624\tbest: 5.3596176 (28)\ttotal: 4m 51s\tremaining: 19m 27s\n",
      "30:\tlearn: 4.7342198\ttest: 5.3635539\tbest: 5.3596176 (28)\ttotal: 5m 1s\tremaining: 19m 17s\n",
      "31:\tlearn: 4.6982837\ttest: 5.3541725\tbest: 5.3541725 (31)\ttotal: 5m 11s\tremaining: 19m 8s\n",
      "32:\tlearn: 4.6723495\ttest: 5.3431301\tbest: 5.3431301 (32)\ttotal: 5m 21s\tremaining: 18m 58s\n",
      "33:\tlearn: 4.6422438\ttest: 5.3306072\tbest: 5.3306072 (33)\ttotal: 5m 31s\tremaining: 18m 50s\n",
      "34:\tlearn: 4.6095828\ttest: 5.3022989\tbest: 5.3022989 (34)\ttotal: 5m 41s\tremaining: 18m 42s\n",
      "35:\tlearn: 4.5568833\ttest: 5.2887702\tbest: 5.2887702 (35)\ttotal: 5m 51s\tremaining: 18m 33s\n",
      "36:\tlearn: 4.5299137\ttest: 5.2894181\tbest: 5.2887702 (35)\ttotal: 6m 1s\tremaining: 18m 23s\n",
      "37:\tlearn: 4.5136701\ttest: 5.2910399\tbest: 5.2887702 (35)\ttotal: 6m 11s\tremaining: 18m 14s\n",
      "38:\tlearn: 4.5089027\ttest: 5.2906875\tbest: 5.2887702 (35)\ttotal: 6m 21s\tremaining: 18m 6s\n",
      "39:\tlearn: 4.4877929\ttest: 5.2917613\tbest: 5.2887702 (35)\ttotal: 6m 31s\tremaining: 17m 56s\n",
      "40:\tlearn: 4.4588791\ttest: 5.2748294\tbest: 5.2748294 (40)\ttotal: 6m 41s\tremaining: 17m 48s\n",
      "41:\tlearn: 4.4286538\ttest: 5.2771287\tbest: 5.2748294 (40)\ttotal: 6m 51s\tremaining: 17m 39s\n",
      "42:\tlearn: 4.4076076\ttest: 5.2795800\tbest: 5.2748294 (40)\ttotal: 7m 1s\tremaining: 17m 29s\n",
      "43:\tlearn: 4.3895122\ttest: 5.2821571\tbest: 5.2748294 (40)\ttotal: 7m 11s\tremaining: 17m 20s\n",
      "44:\tlearn: 4.3780619\ttest: 5.2826507\tbest: 5.2748294 (40)\ttotal: 7m 21s\tremaining: 17m 11s\n",
      "45:\tlearn: 4.3754288\ttest: 5.2820093\tbest: 5.2748294 (40)\ttotal: 7m 32s\tremaining: 17m 3s\n",
      "46:\tlearn: 4.3584703\ttest: 5.2841962\tbest: 5.2748294 (40)\ttotal: 7m 41s\tremaining: 16m 51s\n",
      "47:\tlearn: 4.3437688\ttest: 5.2850564\tbest: 5.2748294 (40)\ttotal: 7m 49s\tremaining: 16m 38s\n",
      "48:\tlearn: 4.3291271\ttest: 5.2871180\tbest: 5.2748294 (40)\ttotal: 7m 58s\tremaining: 16m 25s\n",
      "49:\tlearn: 4.2998079\ttest: 5.2799954\tbest: 5.2748294 (40)\ttotal: 8m 6s\tremaining: 16m 13s\n",
      "50:\tlearn: 4.2746559\ttest: 5.2788528\tbest: 5.2748294 (40)\ttotal: 8m 14s\tremaining: 16m\n",
      "51:\tlearn: 4.2631442\ttest: 5.2790746\tbest: 5.2748294 (40)\ttotal: 8m 23s\tremaining: 15m 48s\n",
      "52:\tlearn: 4.2271174\ttest: 5.2775638\tbest: 5.2748294 (40)\ttotal: 8m 31s\tremaining: 15m 36s\n",
      "53:\tlearn: 4.2213874\ttest: 5.2738204\tbest: 5.2738204 (53)\ttotal: 8m 40s\tremaining: 15m 24s\n",
      "54:\tlearn: 4.2129491\ttest: 5.2737375\tbest: 5.2737375 (54)\ttotal: 8m 48s\tremaining: 15m 13s\n",
      "55:\tlearn: 4.1942442\ttest: 5.2750162\tbest: 5.2737375 (54)\ttotal: 8m 56s\tremaining: 15m\n",
      "56:\tlearn: 4.1724736\ttest: 5.2639994\tbest: 5.2639994 (56)\ttotal: 9m 4s\tremaining: 14m 49s\n",
      "57:\tlearn: 4.1375513\ttest: 5.2557909\tbest: 5.2557909 (57)\ttotal: 9m 12s\tremaining: 14m 36s\n",
      "58:\tlearn: 4.1188535\ttest: 5.2564852\tbest: 5.2557909 (57)\ttotal: 9m 21s\tremaining: 14m 25s\n",
      "59:\tlearn: 4.1056158\ttest: 5.2573429\tbest: 5.2557909 (57)\ttotal: 9m 29s\tremaining: 14m 14s\n",
      "60:\tlearn: 4.0810804\ttest: 5.2588013\tbest: 5.2557909 (57)\ttotal: 9m 38s\tremaining: 14m 3s\n",
      "61:\tlearn: 4.0489735\ttest: 5.2543261\tbest: 5.2543261 (61)\ttotal: 9m 47s\tremaining: 13m 54s\n",
      "62:\tlearn: 4.0302023\ttest: 5.2561841\tbest: 5.2543261 (61)\ttotal: 9m 56s\tremaining: 13m 43s\n",
      "63:\tlearn: 4.0051771\ttest: 5.2582329\tbest: 5.2543261 (61)\ttotal: 10m 3s\tremaining: 13m 31s\n",
      "64:\tlearn: 4.0001267\ttest: 5.2574884\tbest: 5.2543261 (61)\ttotal: 10m 11s\tremaining: 13m 19s\n",
      "65:\tlearn: 3.9876181\ttest: 5.2581822\tbest: 5.2543261 (61)\ttotal: 10m 19s\tremaining: 13m 8s\n",
      "66:\tlearn: 3.9791564\ttest: 5.2580339\tbest: 5.2543261 (61)\ttotal: 10m 26s\tremaining: 12m 56s\n",
      "67:\tlearn: 3.9701342\ttest: 5.2584426\tbest: 5.2543261 (61)\ttotal: 10m 34s\tremaining: 12m 45s\n",
      "68:\tlearn: 3.9272041\ttest: 5.2506221\tbest: 5.2506221 (68)\ttotal: 10m 42s\tremaining: 12m 34s\n",
      "69:\tlearn: 3.9089545\ttest: 5.2525841\tbest: 5.2506221 (68)\ttotal: 10m 50s\tremaining: 12m 23s\n",
      "70:\tlearn: 3.8807646\ttest: 5.2438246\tbest: 5.2438246 (70)\ttotal: 10m 57s\tremaining: 12m 12s\n",
      "71:\tlearn: 3.8649699\ttest: 5.2451613\tbest: 5.2438246 (70)\ttotal: 11m 5s\tremaining: 12m 1s\n",
      "72:\tlearn: 3.8616380\ttest: 5.2443058\tbest: 5.2438246 (70)\ttotal: 11m 13s\tremaining: 11m 50s\n",
      "73:\tlearn: 3.8471226\ttest: 5.2459211\tbest: 5.2438246 (70)\ttotal: 11m 20s\tremaining: 11m 38s\n",
      "74:\tlearn: 3.8177845\ttest: 5.2388108\tbest: 5.2388108 (74)\ttotal: 11m 28s\tremaining: 11m 28s\n",
      "75:\tlearn: 3.8016190\ttest: 5.2410608\tbest: 5.2388108 (74)\ttotal: 11m 35s\tremaining: 11m 17s\n",
      "76:\tlearn: 3.7702629\ttest: 5.2248780\tbest: 5.2248780 (76)\ttotal: 11m 43s\tremaining: 11m 6s\n",
      "77:\tlearn: 3.7576710\ttest: 5.2263870\tbest: 5.2248780 (76)\ttotal: 11m 51s\tremaining: 10m 56s\n",
      "78:\tlearn: 3.7309331\ttest: 5.2183436\tbest: 5.2183436 (78)\ttotal: 11m 59s\tremaining: 10m 46s\n",
      "79:\tlearn: 3.7110384\ttest: 5.2186695\tbest: 5.2183436 (78)\ttotal: 12m 6s\tremaining: 10m 35s\n",
      "80:\tlearn: 3.6826407\ttest: 5.2222795\tbest: 5.2183436 (78)\ttotal: 12m 15s\tremaining: 10m 26s\n",
      "81:\tlearn: 3.6699858\ttest: 5.2240425\tbest: 5.2183436 (78)\ttotal: 12m 24s\tremaining: 10m 17s\n",
      "82:\tlearn: 3.6354668\ttest: 5.2155981\tbest: 5.2155981 (82)\ttotal: 12m 32s\tremaining: 10m 7s\n",
      "83:\tlearn: 3.6333698\ttest: 5.2143785\tbest: 5.2143785 (83)\ttotal: 12m 41s\tremaining: 9m 57s\n",
      "84:\tlearn: 3.6190709\ttest: 5.2165268\tbest: 5.2143785 (83)\ttotal: 12m 48s\tremaining: 9m 47s\n",
      "85:\tlearn: 3.5940969\ttest: 5.2197048\tbest: 5.2143785 (83)\ttotal: 12m 55s\tremaining: 9m 37s\n",
      "86:\tlearn: 3.5811770\ttest: 5.2217867\tbest: 5.2143785 (83)\ttotal: 13m 2s\tremaining: 9m 26s\n",
      "87:\tlearn: 3.5439582\ttest: 5.2250704\tbest: 5.2143785 (83)\ttotal: 13m 10s\tremaining: 9m 17s\n",
      "88:\tlearn: 3.5264667\ttest: 5.2261446\tbest: 5.2143785 (83)\ttotal: 13m 18s\tremaining: 9m 7s\n",
      "89:\tlearn: 3.5137518\ttest: 5.2286864\tbest: 5.2143785 (83)\ttotal: 13m 25s\tremaining: 8m 56s\n",
      "90:\tlearn: 3.5020643\ttest: 5.2296995\tbest: 5.2143785 (83)\ttotal: 13m 31s\tremaining: 8m 46s\n",
      "91:\tlearn: 3.4670391\ttest: 5.2291906\tbest: 5.2143785 (83)\ttotal: 13m 39s\tremaining: 8m 36s\n",
      "92:\tlearn: 3.4306280\ttest: 5.2263351\tbest: 5.2143785 (83)\ttotal: 13m 46s\tremaining: 8m 26s\n",
      "93:\tlearn: 3.4001981\ttest: 5.2134551\tbest: 5.2134551 (93)\ttotal: 13m 53s\tremaining: 8m 16s\n",
      "94:\tlearn: 3.3743092\ttest: 5.2152683\tbest: 5.2134551 (93)\ttotal: 14m\tremaining: 8m 6s\n",
      "95:\tlearn: 3.3648168\ttest: 5.2158851\tbest: 5.2134551 (93)\ttotal: 14m 7s\tremaining: 7m 56s\n",
      "96:\tlearn: 3.3528404\ttest: 5.2167547\tbest: 5.2134551 (93)\ttotal: 14m 14s\tremaining: 7m 47s\n",
      "97:\tlearn: 3.3248963\ttest: 5.2136345\tbest: 5.2134551 (93)\ttotal: 14m 21s\tremaining: 7m 37s\n",
      "98:\tlearn: 3.3117253\ttest: 5.2164467\tbest: 5.2134551 (93)\ttotal: 14m 28s\tremaining: 7m 27s\n",
      "99:\tlearn: 3.3023195\ttest: 5.2168959\tbest: 5.2134551 (93)\ttotal: 14m 35s\tremaining: 7m 17s\n",
      "100:\tlearn: 3.2738514\ttest: 5.2128808\tbest: 5.2128808 (100)\ttotal: 14m 41s\tremaining: 7m 7s\n",
      "101:\tlearn: 3.2703859\ttest: 5.2124319\tbest: 5.2124319 (101)\ttotal: 14m 49s\tremaining: 6m 58s\n",
      "102:\tlearn: 3.2329406\ttest: 5.2072026\tbest: 5.2072026 (102)\ttotal: 14m 58s\tremaining: 6m 50s\n",
      "103:\tlearn: 3.2303171\ttest: 5.2065148\tbest: 5.2065148 (103)\ttotal: 15m 7s\tremaining: 6m 41s\n",
      "104:\tlearn: 3.2177940\ttest: 5.2077254\tbest: 5.2065148 (103)\ttotal: 15m 15s\tremaining: 6m 32s\n",
      "105:\tlearn: 3.1912711\ttest: 5.2007972\tbest: 5.2007972 (105)\ttotal: 15m 24s\tremaining: 6m 23s\n",
      "106:\tlearn: 3.1751674\ttest: 5.1896761\tbest: 5.1896761 (106)\ttotal: 15m 32s\tremaining: 6m 14s\n",
      "107:\tlearn: 3.1524812\ttest: 5.1887752\tbest: 5.1887752 (107)\ttotal: 15m 39s\tremaining: 6m 5s\n",
      "108:\tlearn: 3.1352323\ttest: 5.1893000\tbest: 5.1887752 (107)\ttotal: 15m 46s\tremaining: 5m 56s\n",
      "109:\tlearn: 3.1141043\ttest: 5.1899455\tbest: 5.1887752 (107)\ttotal: 15m 53s\tremaining: 5m 46s\n",
      "110:\tlearn: 3.1047468\ttest: 5.1905144\tbest: 5.1887752 (107)\ttotal: 16m\tremaining: 5m 37s\n",
      "111:\tlearn: 3.0936520\ttest: 5.1873604\tbest: 5.1873604 (111)\ttotal: 16m 6s\tremaining: 5m 28s\n",
      "112:\tlearn: 3.0829766\ttest: 5.1825154\tbest: 5.1825154 (112)\ttotal: 16m 13s\tremaining: 5m 18s\n",
      "113:\tlearn: 3.0634641\ttest: 5.1836135\tbest: 5.1825154 (112)\ttotal: 16m 19s\tremaining: 5m 9s\n",
      "114:\tlearn: 3.0391411\ttest: 5.1793545\tbest: 5.1793545 (114)\ttotal: 16m 26s\tremaining: 5m\n",
      "115:\tlearn: 3.0329690\ttest: 5.1803099\tbest: 5.1793545 (114)\ttotal: 16m 33s\tremaining: 4m 51s\n",
      "116:\tlearn: 3.0171390\ttest: 5.1819431\tbest: 5.1793545 (114)\ttotal: 16m 40s\tremaining: 4m 42s\n",
      "117:\tlearn: 2.9992464\ttest: 5.1809226\tbest: 5.1793545 (114)\ttotal: 16m 46s\tremaining: 4m 32s\n",
      "118:\tlearn: 2.9790350\ttest: 5.1677615\tbest: 5.1677615 (118)\ttotal: 16m 53s\tremaining: 4m 23s\n",
      "119:\tlearn: 2.9627442\ttest: 5.1540395\tbest: 5.1540395 (119)\ttotal: 17m\tremaining: 4m 15s\n",
      "120:\tlearn: 2.9495173\ttest: 5.1441371\tbest: 5.1441371 (120)\ttotal: 17m 6s\tremaining: 4m 6s\n",
      "121:\tlearn: 2.9265251\ttest: 5.1393666\tbest: 5.1393666 (121)\ttotal: 17m 13s\tremaining: 3m 57s\n",
      "122:\tlearn: 2.8987978\ttest: 5.1221247\tbest: 5.1221247 (122)\ttotal: 17m 22s\tremaining: 3m 48s\n",
      "123:\tlearn: 2.8860258\ttest: 5.1223390\tbest: 5.1221247 (122)\ttotal: 17m 31s\tremaining: 3m 40s\n",
      "124:\tlearn: 2.8666098\ttest: 5.1250788\tbest: 5.1221247 (122)\ttotal: 17m 38s\tremaining: 3m 31s\n",
      "125:\tlearn: 2.8502551\ttest: 5.1258923\tbest: 5.1221247 (122)\ttotal: 17m 45s\tremaining: 3m 22s\n",
      "126:\tlearn: 2.8348148\ttest: 5.1286046\tbest: 5.1221247 (122)\ttotal: 17m 52s\tremaining: 3m 14s\n",
      "127:\tlearn: 2.8123601\ttest: 5.1241510\tbest: 5.1221247 (122)\ttotal: 17m 59s\tremaining: 3m 5s\n",
      "128:\tlearn: 2.8099147\ttest: 5.1236732\tbest: 5.1221247 (122)\ttotal: 18m 6s\tremaining: 2m 56s\n",
      "129:\tlearn: 2.8082900\ttest: 5.1229378\tbest: 5.1221247 (122)\ttotal: 18m 12s\tremaining: 2m 48s\n",
      "130:\tlearn: 2.7709673\ttest: 5.1143838\tbest: 5.1143838 (130)\ttotal: 18m 19s\tremaining: 2m 39s\n",
      "131:\tlearn: 2.7499773\ttest: 5.1095237\tbest: 5.1095237 (131)\ttotal: 18m 25s\tremaining: 2m 30s\n",
      "132:\tlearn: 2.7243181\ttest: 5.1091722\tbest: 5.1091722 (132)\ttotal: 18m 32s\tremaining: 2m 22s\n",
      "133:\tlearn: 2.6902220\ttest: 5.1010177\tbest: 5.1010177 (133)\ttotal: 18m 39s\tremaining: 2m 13s\n",
      "134:\tlearn: 2.6898158\ttest: 5.1001472\tbest: 5.1001472 (134)\ttotal: 18m 45s\tremaining: 2m 5s\n",
      "135:\tlearn: 2.6751814\ttest: 5.1020339\tbest: 5.1001472 (134)\ttotal: 18m 52s\tremaining: 1m 56s\n",
      "136:\tlearn: 2.6570152\ttest: 5.0929948\tbest: 5.0929948 (136)\ttotal: 18m 59s\tremaining: 1m 48s\n",
      "137:\tlearn: 2.6441421\ttest: 5.0903499\tbest: 5.0903499 (137)\ttotal: 19m 6s\tremaining: 1m 39s\n",
      "138:\tlearn: 2.6311162\ttest: 5.0927841\tbest: 5.0903499 (137)\ttotal: 19m 12s\tremaining: 1m 31s\n",
      "139:\tlearn: 2.6177581\ttest: 5.0929914\tbest: 5.0903499 (137)\ttotal: 19m 19s\tremaining: 1m 22s\n",
      "140:\tlearn: 2.6106477\ttest: 5.0937107\tbest: 5.0903499 (137)\ttotal: 19m 26s\tremaining: 1m 14s\n",
      "141:\tlearn: 2.6083305\ttest: 5.0935651\tbest: 5.0903499 (137)\ttotal: 19m 33s\tremaining: 1m 6s\n",
      "142:\tlearn: 2.5855891\ttest: 5.0854194\tbest: 5.0854194 (142)\ttotal: 19m 41s\tremaining: 57.8s\n",
      "143:\tlearn: 2.5705394\ttest: 5.0848081\tbest: 5.0848081 (143)\ttotal: 19m 48s\tremaining: 49.5s\n",
      "144:\tlearn: 2.5439592\ttest: 5.0827175\tbest: 5.0827175 (144)\ttotal: 19m 56s\tremaining: 41.3s\n",
      "145:\tlearn: 2.5361801\ttest: 5.0843462\tbest: 5.0827175 (144)\ttotal: 20m 3s\tremaining: 33s\n",
      "146:\tlearn: 2.5136905\ttest: 5.0775500\tbest: 5.0775500 (146)\ttotal: 20m 10s\tremaining: 24.7s\n",
      "147:\tlearn: 2.5062500\ttest: 5.0778718\tbest: 5.0775500 (146)\ttotal: 20m 17s\tremaining: 16.5s\n",
      "148:\tlearn: 2.4834094\ttest: 5.0703886\tbest: 5.0703886 (148)\ttotal: 20m 25s\tremaining: 8.22s\n",
      "149:\tlearn: 2.4596679\ttest: 5.0638969\tbest: 5.0638969 (149)\ttotal: 20m 32s\tremaining: 0us\n",
      "\n",
      "bestTest = 5.063896867\n",
      "bestIteration = 149\n",
      "\n",
      "Model is fitted: True\n",
      "Model params:\n",
      "{'iterations': 150, 'depth': 3, 'loss_function': 'MultiClass', 'random_seed': 63, 'use_best_model': True}\n"
     ]
    }
   ],
   "source": [
    "''' model = CatBoostClassifier(\n",
    "    iterations=100,\n",
    "    depth=3,\n",
    "    loss_function='MultiClass'\n",
    ") '''\n",
    "model = CatBoostClassifier(\n",
    "    random_seed=63,\n",
    "    iterations=150,\n",
    "    # learning_rate=0.25,\n",
    "    depth=3,\n",
    "    loss_function='MultiClass',\n",
    "    use_best_model=True\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    X_train, y_train,\n",
    "    cat_features=cat_features,\n",
    "    eval_set=(X_validation, y_validation),\n",
    "    # verbose=False\n",
    ")\n",
    "\n",
    "print('Model is fitted: ' + str(model.is_fitted()))\n",
    "print('Model params:')\n",
    "print(model.get_params())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_model(\"../models/withValidation/modelD3130.cbm\",\n",
    "                    format=\"cbm\",\n",
    "                    export_parameters=None,\n",
    "                    pool=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.217853\n",
      "0:\tlearn: 5.2046555\ttest: 5.2134757\tbest: 5.2134757 (0)\ttotal: 7.7s\tremaining: 19m 6s\n",
      "1:\tlearn: 5.1634807\ttest: 5.2120469\tbest: 5.2120469 (1)\ttotal: 14.7s\tremaining: 18m 8s\n",
      "2:\tlearn: 5.1453802\ttest: 5.2108142\tbest: 5.2108142 (2)\ttotal: 22.7s\tremaining: 18m 33s\n",
      "3:\tlearn: 5.1177736\ttest: 5.2034173\tbest: 5.2034173 (3)\ttotal: 30.6s\tremaining: 18m 35s\n",
      "4:\tlearn: 5.1065871\ttest: 5.1993662\tbest: 5.1993662 (4)\ttotal: 37.3s\tremaining: 18m 2s\n",
      "5:\tlearn: 5.0825682\ttest: 5.1950779\tbest: 5.1950779 (5)\ttotal: 43.7s\tremaining: 17m 29s\n",
      "6:\tlearn: 5.0498946\ttest: 5.1881394\tbest: 5.1881394 (6)\ttotal: 50.4s\tremaining: 17m 8s\n",
      "7:\tlearn: 5.0382427\ttest: 5.1839985\tbest: 5.1839985 (7)\ttotal: 57.6s\tremaining: 17m 2s\n",
      "8:\tlearn: 5.0219381\ttest: 5.1797768\tbest: 5.1797768 (8)\ttotal: 1m 4s\tremaining: 16m 46s\n",
      "9:\tlearn: 5.0060330\ttest: 5.1758371\tbest: 5.1758371 (9)\ttotal: 1m 10s\tremaining: 16m 33s\n",
      "10:\tlearn: 4.9822763\ttest: 5.1725216\tbest: 5.1725216 (10)\ttotal: 1m 17s\tremaining: 16m 21s\n",
      "11:\tlearn: 4.9589742\ttest: 5.1645830\tbest: 5.1645830 (11)\ttotal: 1m 24s\tremaining: 16m 9s\n",
      "12:\tlearn: 4.9365912\ttest: 5.1526281\tbest: 5.1526281 (12)\ttotal: 1m 30s\tremaining: 15m 56s\n",
      "13:\tlearn: 4.8994034\ttest: 5.1469726\tbest: 5.1469726 (13)\ttotal: 1m 37s\tremaining: 15m 44s\n",
      "14:\tlearn: 4.8911917\ttest: 5.1445671\tbest: 5.1445671 (14)\ttotal: 1m 43s\tremaining: 15m 32s\n",
      "15:\tlearn: 4.8780312\ttest: 5.1431758\tbest: 5.1431758 (15)\ttotal: 1m 50s\tremaining: 15m 23s\n",
      "16:\tlearn: 4.8636039\ttest: 5.1349912\tbest: 5.1349912 (16)\ttotal: 1m 56s\tremaining: 15m 14s\n",
      "17:\tlearn: 4.8475989\ttest: 5.1347943\tbest: 5.1347943 (17)\ttotal: 2m 3s\tremaining: 15m 4s\n",
      "18:\tlearn: 4.8324605\ttest: 5.1304498\tbest: 5.1304498 (18)\ttotal: 2m 9s\tremaining: 14m 54s\n",
      "19:\tlearn: 4.8090234\ttest: 5.1256169\tbest: 5.1256169 (19)\ttotal: 2m 16s\tremaining: 14m 46s\n",
      "20:\tlearn: 4.7782886\ttest: 5.1097165\tbest: 5.1097165 (20)\ttotal: 2m 23s\tremaining: 14m 40s\n",
      "21:\tlearn: 4.7674988\ttest: 5.1088306\tbest: 5.1088306 (21)\ttotal: 2m 29s\tremaining: 14m 31s\n",
      "22:\tlearn: 4.7284996\ttest: 5.0924775\tbest: 5.0924775 (22)\ttotal: 2m 36s\tremaining: 14m 22s\n",
      "23:\tlearn: 4.7166310\ttest: 5.0887544\tbest: 5.0887544 (23)\ttotal: 2m 42s\tremaining: 14m 12s\n",
      "24:\tlearn: 4.6933642\ttest: 5.0853282\tbest: 5.0853282 (24)\ttotal: 2m 48s\tremaining: 14m 3s\n",
      "25:\tlearn: 4.6828111\ttest: 5.0846060\tbest: 5.0846060 (25)\ttotal: 2m 55s\tremaining: 13m 54s\n",
      "26:\tlearn: 4.6705155\ttest: 5.0808026\tbest: 5.0808026 (26)\ttotal: 3m 1s\tremaining: 13m 47s\n",
      "27:\tlearn: 4.6475504\ttest: 5.0789509\tbest: 5.0789509 (27)\ttotal: 3m 7s\tremaining: 13m 38s\n",
      "28:\tlearn: 4.6392160\ttest: 5.0773403\tbest: 5.0773403 (28)\ttotal: 3m 14s\tremaining: 13m 30s\n",
      "29:\tlearn: 4.6136639\ttest: 5.0715620\tbest: 5.0715620 (29)\ttotal: 3m 20s\tremaining: 13m 22s\n",
      "30:\tlearn: 4.6036036\ttest: 5.0694543\tbest: 5.0694543 (30)\ttotal: 3m 27s\tremaining: 13m 14s\n",
      "31:\tlearn: 4.5967756\ttest: 5.0682176\tbest: 5.0682176 (31)\ttotal: 3m 33s\tremaining: 13m 7s\n",
      "32:\tlearn: 4.5898014\ttest: 5.0639185\tbest: 5.0639185 (32)\ttotal: 3m 39s\tremaining: 12m 59s\n",
      "33:\tlearn: 4.5559976\ttest: 5.0502940\tbest: 5.0502940 (33)\ttotal: 3m 46s\tremaining: 12m 52s\n",
      "34:\tlearn: 4.5124951\ttest: 5.0457295\tbest: 5.0457295 (34)\ttotal: 3m 52s\tremaining: 12m 44s\n",
      "35:\tlearn: 4.4851697\ttest: 5.0452129\tbest: 5.0452129 (35)\ttotal: 3m 58s\tremaining: 12m 36s\n",
      "36:\tlearn: 4.4388117\ttest: 5.0354930\tbest: 5.0354930 (36)\ttotal: 4m 5s\tremaining: 12m 29s\n",
      "37:\tlearn: 4.4348559\ttest: 5.0333679\tbest: 5.0333679 (37)\ttotal: 4m 11s\tremaining: 12m 21s\n",
      "38:\tlearn: 4.4227934\ttest: 5.0322522\tbest: 5.0322522 (38)\ttotal: 4m 17s\tremaining: 12m 14s\n",
      "39:\tlearn: 4.4209210\ttest: 5.0298734\tbest: 5.0298734 (39)\ttotal: 4m 24s\tremaining: 12m 7s\n",
      "40:\tlearn: 4.4058922\ttest: 5.0290402\tbest: 5.0290402 (40)\ttotal: 4m 30s\tremaining: 12m\n",
      "41:\tlearn: 4.3835425\ttest: 5.0286113\tbest: 5.0286113 (41)\ttotal: 4m 37s\tremaining: 11m 52s\n",
      "42:\tlearn: 4.3687223\ttest: 5.0256684\tbest: 5.0256684 (42)\ttotal: 4m 43s\tremaining: 11m 45s\n",
      "43:\tlearn: 4.3584767\ttest: 5.0256141\tbest: 5.0256141 (43)\ttotal: 4m 49s\tremaining: 11m 38s\n",
      "44:\tlearn: 4.3490135\ttest: 5.0232803\tbest: 5.0232803 (44)\ttotal: 4m 56s\tremaining: 11m 31s\n",
      "45:\tlearn: 4.3209862\ttest: 5.0092023\tbest: 5.0092023 (45)\ttotal: 5m 2s\tremaining: 11m 23s\n",
      "46:\tlearn: 4.2992015\ttest: 4.9970456\tbest: 4.9970456 (46)\ttotal: 5m 8s\tremaining: 11m 16s\n",
      "47:\tlearn: 4.2750004\ttest: 4.9872275\tbest: 4.9872275 (47)\ttotal: 5m 15s\tremaining: 11m 9s\n",
      "48:\tlearn: 4.2435843\ttest: 4.9836113\tbest: 4.9836113 (48)\ttotal: 5m 21s\tremaining: 11m 2s\n",
      "49:\tlearn: 4.2188443\ttest: 4.9798794\tbest: 4.9798794 (49)\ttotal: 5m 28s\tremaining: 10m 56s\n",
      "50:\tlearn: 4.2149353\ttest: 4.9783299\tbest: 4.9783299 (50)\ttotal: 5m 34s\tremaining: 10m 49s\n",
      "51:\tlearn: 4.2060491\ttest: 4.9777186\tbest: 4.9777186 (51)\ttotal: 5m 40s\tremaining: 10m 41s\n",
      "52:\tlearn: 4.1797552\ttest: 4.9780670\tbest: 4.9777186 (51)\ttotal: 5m 46s\tremaining: 10m 34s\n",
      "53:\tlearn: 4.1444345\ttest: 4.9796466\tbest: 4.9777186 (51)\ttotal: 5m 53s\tremaining: 10m 28s\n",
      "54:\tlearn: 4.1426042\ttest: 4.9779021\tbest: 4.9777186 (51)\ttotal: 5m 59s\tremaining: 10m 21s\n",
      "55:\tlearn: 4.1392562\ttest: 4.9767141\tbest: 4.9767141 (55)\ttotal: 6m 5s\tremaining: 10m 14s\n",
      "56:\tlearn: 4.1191118\ttest: 4.9656533\tbest: 4.9656533 (56)\ttotal: 6m 12s\tremaining: 10m 7s\n",
      "57:\tlearn: 4.1141388\ttest: 4.9650584\tbest: 4.9650584 (57)\ttotal: 6m 18s\tremaining: 10m\n",
      "58:\tlearn: 4.1114185\ttest: 4.9627444\tbest: 4.9627444 (58)\ttotal: 6m 24s\tremaining: 9m 53s\n",
      "59:\tlearn: 4.0961834\ttest: 4.9630652\tbest: 4.9627444 (58)\ttotal: 6m 31s\tremaining: 9m 47s\n",
      "60:\tlearn: 4.0824285\ttest: 4.9614635\tbest: 4.9614635 (60)\ttotal: 6m 38s\tremaining: 9m 40s\n",
      "61:\tlearn: 4.0757769\ttest: 4.9608610\tbest: 4.9608610 (61)\ttotal: 6m 44s\tremaining: 9m 34s\n",
      "62:\tlearn: 4.0599965\ttest: 4.9619452\tbest: 4.9608610 (61)\ttotal: 6m 51s\tremaining: 9m 27s\n",
      "63:\tlearn: 4.0549039\ttest: 4.9614556\tbest: 4.9608610 (61)\ttotal: 6m 57s\tremaining: 9m 20s\n",
      "64:\tlearn: 4.0137626\ttest: 4.9627482\tbest: 4.9608610 (61)\ttotal: 7m 3s\tremaining: 9m 14s\n",
      "65:\tlearn: 3.9758711\ttest: 4.9629093\tbest: 4.9608610 (61)\ttotal: 7m 10s\tremaining: 9m 7s\n",
      "66:\tlearn: 3.9750766\ttest: 4.9616138\tbest: 4.9608610 (61)\ttotal: 7m 16s\tremaining: 9m 1s\n",
      "67:\tlearn: 3.9514270\ttest: 4.9581325\tbest: 4.9581325 (67)\ttotal: 7m 23s\tremaining: 8m 54s\n",
      "68:\tlearn: 3.9482757\ttest: 4.9576537\tbest: 4.9576537 (68)\ttotal: 7m 29s\tremaining: 8m 48s\n",
      "69:\tlearn: 3.9427487\ttest: 4.9561654\tbest: 4.9561654 (69)\ttotal: 7m 36s\tremaining: 8m 41s\n",
      "70:\tlearn: 3.9061534\ttest: 4.9578708\tbest: 4.9561654 (69)\ttotal: 7m 42s\tremaining: 8m 35s\n",
      "71:\tlearn: 3.8905955\ttest: 4.9570273\tbest: 4.9561654 (69)\ttotal: 7m 49s\tremaining: 8m 28s\n",
      "72:\tlearn: 3.8719830\ttest: 4.9580934\tbest: 4.9561654 (69)\ttotal: 7m 55s\tremaining: 8m 21s\n",
      "73:\tlearn: 3.8595488\ttest: 4.9541257\tbest: 4.9541257 (73)\ttotal: 8m 2s\tremaining: 8m 15s\n",
      "74:\tlearn: 3.8390899\ttest: 4.9446002\tbest: 4.9446002 (74)\ttotal: 8m 8s\tremaining: 8m 8s\n",
      "75:\tlearn: 3.8226235\ttest: 4.9456821\tbest: 4.9446002 (74)\ttotal: 8m 15s\tremaining: 8m 2s\n",
      "76:\tlearn: 3.8047423\ttest: 4.9466770\tbest: 4.9446002 (74)\ttotal: 8m 21s\tremaining: 7m 55s\n",
      "77:\tlearn: 3.8010171\ttest: 4.9443472\tbest: 4.9443472 (77)\ttotal: 8m 27s\tremaining: 7m 48s\n",
      "78:\tlearn: 3.7860190\ttest: 4.9443963\tbest: 4.9443472 (77)\ttotal: 8m 34s\tremaining: 7m 42s\n",
      "79:\tlearn: 3.7688362\ttest: 4.9451578\tbest: 4.9443472 (77)\ttotal: 8m 40s\tremaining: 7m 35s\n",
      "80:\tlearn: 3.7453467\ttest: 4.9460815\tbest: 4.9443472 (77)\ttotal: 8m 46s\tremaining: 7m 28s\n",
      "81:\tlearn: 3.7427287\ttest: 4.9451753\tbest: 4.9443472 (77)\ttotal: 8m 53s\tremaining: 7m 22s\n",
      "82:\tlearn: 3.7372206\ttest: 4.9451469\tbest: 4.9443472 (77)\ttotal: 8m 59s\tremaining: 7m 15s\n",
      "83:\tlearn: 3.7219235\ttest: 4.9462311\tbest: 4.9443472 (77)\ttotal: 9m 5s\tremaining: 7m 8s\n",
      "84:\tlearn: 3.6875060\ttest: 4.9490521\tbest: 4.9443472 (77)\ttotal: 9m 11s\tremaining: 7m 1s\n",
      "85:\tlearn: 3.6534286\ttest: 4.9496105\tbest: 4.9443472 (77)\ttotal: 9m 17s\tremaining: 6m 55s\n",
      "86:\tlearn: 3.6493211\ttest: 4.9494884\tbest: 4.9443472 (77)\ttotal: 9m 24s\tremaining: 6m 48s\n",
      "87:\tlearn: 3.6354963\ttest: 4.9499102\tbest: 4.9443472 (77)\ttotal: 9m 30s\tremaining: 6m 41s\n",
      "88:\tlearn: 3.6224996\ttest: 4.9506562\tbest: 4.9443472 (77)\ttotal: 9m 36s\tremaining: 6m 35s\n",
      "89:\tlearn: 3.6038686\ttest: 4.9398645\tbest: 4.9398645 (89)\ttotal: 9m 43s\tremaining: 6m 28s\n",
      "90:\tlearn: 3.5895587\ttest: 4.9407963\tbest: 4.9398645 (89)\ttotal: 9m 49s\tremaining: 6m 22s\n",
      "91:\tlearn: 3.5674930\ttest: 4.9355962\tbest: 4.9355962 (91)\ttotal: 9m 55s\tremaining: 6m 15s\n",
      "92:\tlearn: 3.5273570\ttest: 4.9289909\tbest: 4.9289909 (92)\ttotal: 10m 1s\tremaining: 6m 8s\n",
      "93:\tlearn: 3.5224432\ttest: 4.9288108\tbest: 4.9288108 (93)\ttotal: 10m 8s\tremaining: 6m 2s\n",
      "94:\tlearn: 3.5180391\ttest: 4.9285664\tbest: 4.9285664 (94)\ttotal: 10m 14s\tremaining: 5m 55s\n",
      "95:\tlearn: 3.4742475\ttest: 4.9308729\tbest: 4.9285664 (94)\ttotal: 10m 20s\tremaining: 5m 49s\n",
      "96:\tlearn: 3.4351444\ttest: 4.9256318\tbest: 4.9256318 (96)\ttotal: 10m 26s\tremaining: 5m 42s\n",
      "97:\tlearn: 3.4278030\ttest: 4.9230686\tbest: 4.9230686 (97)\ttotal: 10m 33s\tremaining: 5m 36s\n",
      "98:\tlearn: 3.3952820\ttest: 4.9154127\tbest: 4.9154127 (98)\ttotal: 10m 39s\tremaining: 5m 29s\n",
      "99:\tlearn: 3.3711695\ttest: 4.9062719\tbest: 4.9062719 (99)\ttotal: 10m 45s\tremaining: 5m 22s\n",
      "100:\tlearn: 3.3411711\ttest: 4.9047420\tbest: 4.9047420 (100)\ttotal: 10m 52s\tremaining: 5m 16s\n",
      "101:\tlearn: 3.3386179\ttest: 4.9044531\tbest: 4.9044531 (101)\ttotal: 10m 58s\tremaining: 5m 9s\n",
      "102:\tlearn: 3.3060675\ttest: 4.8989980\tbest: 4.8989980 (102)\ttotal: 11m 4s\tremaining: 5m 3s\n",
      "103:\tlearn: 3.2871404\ttest: 4.9009366\tbest: 4.8989980 (102)\ttotal: 11m 11s\tremaining: 4m 56s\n",
      "104:\tlearn: 3.2632110\ttest: 4.8903139\tbest: 4.8903139 (104)\ttotal: 11m 17s\tremaining: 4m 50s\n",
      "105:\tlearn: 3.2292442\ttest: 4.8742431\tbest: 4.8742431 (105)\ttotal: 11m 23s\tremaining: 4m 43s\n",
      "106:\tlearn: 3.2267675\ttest: 4.8741257\tbest: 4.8741257 (106)\ttotal: 11m 29s\tremaining: 4m 37s\n",
      "107:\tlearn: 3.2069065\ttest: 4.8757318\tbest: 4.8741257 (106)\ttotal: 11m 36s\tremaining: 4m 30s\n",
      "108:\tlearn: 3.2055642\ttest: 4.8751826\tbest: 4.8741257 (106)\ttotal: 11m 42s\tremaining: 4m 24s\n",
      "109:\tlearn: 3.1714791\ttest: 4.8673250\tbest: 4.8673250 (109)\ttotal: 11m 48s\tremaining: 4m 17s\n",
      "110:\tlearn: 3.1348750\ttest: 4.8574431\tbest: 4.8574431 (110)\ttotal: 11m 55s\tremaining: 4m 11s\n",
      "111:\tlearn: 3.1181733\ttest: 4.8579699\tbest: 4.8574431 (110)\ttotal: 12m 1s\tremaining: 4m 4s\n",
      "112:\tlearn: 3.1172546\ttest: 4.8572269\tbest: 4.8572269 (112)\ttotal: 12m 7s\tremaining: 3m 58s\n",
      "113:\tlearn: 3.1085223\ttest: 4.8575612\tbest: 4.8572269 (112)\ttotal: 12m 14s\tremaining: 3m 51s\n",
      "114:\tlearn: 3.0919191\ttest: 4.8486135\tbest: 4.8486135 (114)\ttotal: 12m 20s\tremaining: 3m 45s\n",
      "115:\tlearn: 3.0582812\ttest: 4.8506401\tbest: 4.8486135 (114)\ttotal: 12m 26s\tremaining: 3m 38s\n",
      "116:\tlearn: 3.0316566\ttest: 4.8323746\tbest: 4.8323746 (116)\ttotal: 12m 33s\tremaining: 3m 32s\n",
      "117:\tlearn: 3.0291610\ttest: 4.8321707\tbest: 4.8321707 (117)\ttotal: 12m 40s\tremaining: 3m 26s\n",
      "118:\tlearn: 3.0190855\ttest: 4.8311845\tbest: 4.8311845 (118)\ttotal: 12m 46s\tremaining: 3m 19s\n",
      "119:\tlearn: 2.9979551\ttest: 4.8333454\tbest: 4.8311845 (118)\ttotal: 12m 52s\tremaining: 3m 13s\n",
      "120:\tlearn: 2.9603154\ttest: 4.8318790\tbest: 4.8311845 (118)\ttotal: 12m 58s\tremaining: 3m 6s\n",
      "121:\tlearn: 2.9384553\ttest: 4.8351261\tbest: 4.8311845 (118)\ttotal: 13m 5s\tremaining: 3m\n",
      "122:\tlearn: 2.9008332\ttest: 4.8271771\tbest: 4.8271771 (122)\ttotal: 13m 11s\tremaining: 2m 53s\n",
      "123:\tlearn: 2.8904736\ttest: 4.8279957\tbest: 4.8271771 (122)\ttotal: 13m 17s\tremaining: 2m 47s\n",
      "124:\tlearn: 2.8674285\ttest: 4.8273312\tbest: 4.8271771 (122)\ttotal: 13m 24s\tremaining: 2m 40s\n",
      "125:\tlearn: 2.8499685\ttest: 4.8275304\tbest: 4.8271771 (122)\ttotal: 13m 30s\tremaining: 2m 34s\n",
      "126:\tlearn: 2.8392794\ttest: 4.8287564\tbest: 4.8271771 (122)\ttotal: 13m 37s\tremaining: 2m 28s\n",
      "127:\tlearn: 2.8169263\ttest: 4.8322105\tbest: 4.8271771 (122)\ttotal: 13m 43s\tremaining: 2m 21s\n",
      "128:\tlearn: 2.7989344\ttest: 4.8348517\tbest: 4.8271771 (122)\ttotal: 13m 50s\tremaining: 2m 15s\n",
      "129:\tlearn: 2.7843511\ttest: 4.8353443\tbest: 4.8271771 (122)\ttotal: 13m 56s\tremaining: 2m 8s\n",
      "130:\tlearn: 2.7687186\ttest: 4.8373383\tbest: 4.8271771 (122)\ttotal: 14m 3s\tremaining: 2m 2s\n",
      "131:\tlearn: 2.7440521\ttest: 4.8301008\tbest: 4.8271771 (122)\ttotal: 14m 9s\tremaining: 1m 55s\n",
      "132:\tlearn: 2.7394911\ttest: 4.8301523\tbest: 4.8271771 (122)\ttotal: 14m 16s\tremaining: 1m 49s\n",
      "133:\tlearn: 2.7153494\ttest: 4.8293445\tbest: 4.8271771 (122)\ttotal: 14m 22s\tremaining: 1m 43s\n",
      "134:\tlearn: 2.7088056\ttest: 4.8290107\tbest: 4.8271771 (122)\ttotal: 14m 29s\tremaining: 1m 36s\n",
      "135:\tlearn: 2.7053873\ttest: 4.8292512\tbest: 4.8271771 (122)\ttotal: 14m 35s\tremaining: 1m 30s\n",
      "136:\tlearn: 2.6698658\ttest: 4.8243457\tbest: 4.8243457 (136)\ttotal: 14m 42s\tremaining: 1m 23s\n",
      "137:\tlearn: 2.6576236\ttest: 4.8249087\tbest: 4.8243457 (136)\ttotal: 14m 48s\tremaining: 1m 17s\n",
      "138:\tlearn: 2.6296339\ttest: 4.8301065\tbest: 4.8243457 (136)\ttotal: 14m 55s\tremaining: 1m 10s\n",
      "139:\tlearn: 2.6192917\ttest: 4.8278621\tbest: 4.8243457 (136)\ttotal: 15m 1s\tremaining: 1m 4s\n",
      "140:\tlearn: 2.6082783\ttest: 4.8284759\tbest: 4.8243457 (136)\ttotal: 15m 7s\tremaining: 57.9s\n",
      "141:\tlearn: 2.5860777\ttest: 4.8296426\tbest: 4.8243457 (136)\ttotal: 15m 14s\tremaining: 51.5s\n",
      "142:\tlearn: 2.5820047\ttest: 4.8297678\tbest: 4.8243457 (136)\ttotal: 15m 20s\tremaining: 45.1s\n",
      "143:\tlearn: 2.5559939\ttest: 4.8285098\tbest: 4.8243457 (136)\ttotal: 15m 26s\tremaining: 38.6s\n",
      "144:\tlearn: 2.5410838\ttest: 4.8295027\tbest: 4.8243457 (136)\ttotal: 15m 33s\tremaining: 32.2s\n",
      "145:\tlearn: 2.5252482\ttest: 4.8316138\tbest: 4.8243457 (136)\ttotal: 15m 39s\tremaining: 25.7s\n",
      "146:\tlearn: 2.4922378\ttest: 4.8234842\tbest: 4.8234842 (146)\ttotal: 15m 46s\tremaining: 19.3s\n",
      "147:\tlearn: 2.4588556\ttest: 4.8187108\tbest: 4.8187108 (147)\ttotal: 15m 52s\tremaining: 12.9s\n",
      "148:\tlearn: 2.4441610\ttest: 4.8112033\tbest: 4.8112033 (148)\ttotal: 15m 58s\tremaining: 6.43s\n",
      "149:\tlearn: 2.4389888\ttest: 4.8054915\tbest: 4.8054915 (149)\ttotal: 16m 5s\tremaining: 0us\n",
      "\n",
      "bestTest = 4.805491473\n",
      "bestIteration = 149\n",
      "\n",
      "Model 2 is fitted: True\n",
      "Model 2 params:\n",
      "{'iterations': 150, 'depth': 3, 'loss_function': 'MultiClass', 'random_seed': 63, 'use_best_model': True}\n"
     ]
    }
   ],
   "source": [
    "model2 = CatBoostClassifier(\n",
    "    random_seed=63,\n",
    "    iterations=150,\n",
    "    # learning_rate=0.25,\n",
    "    depth=3,\n",
    "    loss_function='MultiClass',\n",
    "    use_best_model=True\n",
    ")\n",
    "\n",
    "model2.fit(\n",
    "    X_train, y_train,\n",
    "    cat_features=cat_features,\n",
    "    eval_set=(X_validation, y_validation),\n",
    "    init_model=model\n",
    "    # verbose=False\n",
    ")\n",
    "\n",
    "print('Model 2 is fitted: ' + str(model2.is_fitted()))\n",
    "print('Model 2 params:')\n",
    "print(model2.get_params())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.00315492 0.00318327 0.00318327 ... 0.00318327 0.0031294  0.00310324]\n",
      " [0.00315492 0.00318327 0.00318327 ... 0.00318327 0.0031294  0.00310324]\n",
      " [0.00315492 0.00318327 0.00318327 ... 0.00318327 0.0031294  0.00310324]\n",
      " ...\n",
      " [0.00315492 0.00318327 0.00318327 ... 0.00318327 0.0031294  0.00310324]\n",
      " [0.00314886 0.00312168 0.00312168 ... 0.00312168 0.00312339 0.00312365]\n",
      " [0.00315492 0.00318327 0.00318327 ... 0.00318327 0.0031294  0.00310324]]\n"
     ]
    }
   ],
   "source": [
    "validation_df = pandas.read_csv('../data/perros_predict_v3.csv')\n",
    "y_validation = train_df.Mascota\n",
    "X_validation = train_df.drop('Mascota', axis=1)\n",
    "X_validation.fillna(\"NaN\", inplace=True)\n",
    "\n",
    "X_train = X\n",
    "y_train = y\n",
    "# X_validation =\n",
    "print(model.predict_proba(X_validation))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1157]\n",
      " [1157]\n",
      " [1157]\n",
      " [1157]\n",
      " [  34]\n",
      " [1074]\n",
      " [1157]\n",
      " [  34]\n",
      " [1074]\n",
      " [4512]\n",
      " [1157]\n",
      " [  12]\n",
      " [  13]\n",
      " [1470]\n",
      " [  34]\n",
      " [  16]\n",
      " [1074]\n",
      " [1279]\n",
      " [  12]\n",
      " [  34]\n",
      " [  34]\n",
      " [  12]\n",
      " [  34]\n",
      " [  34]\n",
      " [4512]\n",
      " [  34]\n",
      " [6064]\n",
      " [1279]\n",
      " [1074]\n",
      " [  34]\n",
      " [  31]\n",
      " [1800]\n",
      " [4307]\n",
      " [  34]\n",
      " [1157]\n",
      " [6065]\n",
      " [1470]\n",
      " [1526]\n",
      " [  39]\n",
      " [  34]\n",
      " [1157]\n",
      " [6065]\n",
      " [  13]\n",
      " [1526]\n",
      " [1074]\n",
      " [1074]\n",
      " [6065]\n",
      " [1279]\n",
      " [  34]\n",
      " [  34]\n",
      " [1074]\n",
      " [  34]\n",
      " [1157]\n",
      " [  34]\n",
      " [1470]\n",
      " [4512]\n",
      " [1183]\n",
      " [1470]\n",
      " [6065]\n",
      " [1800]\n",
      " [1074]\n",
      " [6065]\n",
      " [6065]\n",
      " [6065]\n",
      " [1800]\n",
      " [1279]\n",
      " [1470]\n",
      " [1144]\n",
      " [1036]\n",
      " [1074]\n",
      " [1800]\n",
      " [1470]\n",
      " [6065]\n",
      " [1800]\n",
      " [1401]\n",
      " [4512]\n",
      " [1066]\n",
      " [  34]\n",
      " [6065]\n",
      " [6065]\n",
      " [  34]\n",
      " [1074]\n",
      " [  34]\n",
      " [  34]\n",
      " [1157]\n",
      " [1800]\n",
      " [1279]\n",
      " [1401]\n",
      " [1800]\n",
      " [1800]\n",
      " [1401]\n",
      " [1144]\n",
      " [1800]\n",
      " [3507]\n",
      " [4307]\n",
      " [  34]\n",
      " [3631]\n",
      " [  34]\n",
      " [  34]\n",
      " [1761]\n",
      " [  34]\n",
      " [1800]\n",
      " [3592]\n",
      " [1144]\n",
      " [1640]\n",
      " [1157]\n",
      " [1800]\n",
      " [3631]\n",
      " [1144]\n",
      " [4512]\n",
      " [1800]\n",
      " [1800]\n",
      " [  34]\n",
      " [1183]\n",
      " [3524]\n",
      " [1401]\n",
      " [  34]\n",
      " [1470]\n",
      " [1401]\n",
      " [1470]\n",
      " [1279]\n",
      " [1215]\n",
      " [6065]\n",
      " [1800]\n",
      " [6064]\n",
      " [6019]\n",
      " [1279]\n",
      " [1144]\n",
      " [1800]\n",
      " [3914]\n",
      " [3507]\n",
      " [4229]\n",
      " [4229]\n",
      " [1279]\n",
      " [1036]\n",
      " [6065]\n",
      " [1821]\n",
      " [1183]\n",
      " [  39]\n",
      " [4512]\n",
      " [  34]\n",
      " [1238]\n",
      " [6065]\n",
      " [1279]\n",
      " [3631]\n",
      " [  34]\n",
      " [  34]\n",
      " [1036]\n",
      " [6065]\n",
      " [1401]\n",
      " [1800]\n",
      " [1640]\n",
      " [4307]\n",
      " [1074]\n",
      " [1640]\n",
      " [3524]\n",
      " [4307]\n",
      " [6065]\n",
      " [1470]\n",
      " [4512]\n",
      " [1144]\n",
      " [4229]\n",
      " [1401]\n",
      " [3914]\n",
      " [  34]\n",
      " [1800]\n",
      " [6065]\n",
      " [1470]\n",
      " [1401]\n",
      " [  34]\n",
      " [4307]\n",
      " [6065]\n",
      " [1800]\n",
      " [6065]\n",
      " [1279]\n",
      " [1279]\n",
      " [1066]\n",
      " [4307]\n",
      " [6065]\n",
      " [1144]\n",
      " [1401]\n",
      " [6065]\n",
      " [1801]\n",
      " [  34]\n",
      " [6065]\n",
      " [1800]\n",
      " [1821]\n",
      " [3631]\n",
      " [6019]\n",
      " [1157]\n",
      " [1183]\n",
      " [6065]\n",
      " [  16]\n",
      " [6065]\n",
      " [1468]\n",
      " [1144]\n",
      " [  34]\n",
      " [1036]\n",
      " [1470]\n",
      " [  34]\n",
      " [1640]\n",
      " [3631]\n",
      " [  34]\n",
      " [1074]\n",
      " [1761]\n",
      " [6064]\n",
      " [1144]\n",
      " [3914]\n",
      " [1183]\n",
      " [4229]\n",
      " [  34]\n",
      " [4512]\n",
      " [4307]\n",
      " [6066]\n",
      " [1401]\n",
      " [1800]\n",
      " [6040]\n",
      " [4512]\n",
      " [1526]\n",
      " [  34]\n",
      " [1215]\n",
      " [3631]\n",
      " [  34]\n",
      " [1509]\n",
      " [1157]\n",
      " [1157]\n",
      " [  34]\n",
      " [  34]\n",
      " [4512]\n",
      " [6065]\n",
      " [1401]\n",
      " [1401]\n",
      " [1526]\n",
      " [1401]\n",
      " [1279]\n",
      " [6065]\n",
      " [1401]\n",
      " [1074]\n",
      " [1401]\n",
      " [1800]\n",
      " [1800]\n",
      " [1800]\n",
      " [1144]\n",
      " [1546]\n",
      " [1401]\n",
      " [  34]\n",
      " [4229]\n",
      " [6019]\n",
      " [  34]\n",
      " [6064]\n",
      " [1800]\n",
      " [1640]\n",
      " [1800]\n",
      " [6065]\n",
      " [6065]\n",
      " [1144]\n",
      " [6066]\n",
      " [1279]\n",
      " [4229]\n",
      " [1800]\n",
      " [1800]\n",
      " [6065]\n",
      " [6065]\n",
      " [1640]\n",
      " [1800]\n",
      " [  34]\n",
      " [6066]\n",
      " [4512]\n",
      " [  34]\n",
      " [1640]\n",
      " [  34]\n",
      " [4243]\n",
      " [3524]\n",
      " [  39]\n",
      " [3524]\n",
      " [6075]\n",
      " [  34]\n",
      " [1401]\n",
      " [  34]\n",
      " [1144]\n",
      " [  34]\n",
      " [1800]\n",
      " [3524]\n",
      " [1470]\n",
      " [1470]\n",
      " [  34]\n",
      " [1470]\n",
      " [1401]\n",
      " [1800]\n",
      " [1800]\n",
      " [1470]\n",
      " [  34]\n",
      " [1470]\n",
      " [1761]\n",
      " [1144]\n",
      " [6065]\n",
      " [1800]\n",
      " [1526]\n",
      " [1470]\n",
      " [1800]\n",
      " [1801]\n",
      " [4307]\n",
      " [1821]\n",
      " [6065]\n",
      " [6065]\n",
      " [1761]\n",
      " [1144]\n",
      " [1800]\n",
      " [  34]\n",
      " [3507]\n",
      " [3914]\n",
      " [1821]\n",
      " [1036]\n",
      " [1183]\n",
      " [1526]\n",
      " [1800]\n",
      " [1546]\n",
      " [1470]\n",
      " [1821]\n",
      " [1470]]\n"
     ]
    }
   ],
   "source": [
    "print(model.predict(X_validation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature Id</th>\n",
       "      <th>Importances</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Largo de pelaje</td>\n",
       "      <td>37.479364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Color de ojos</td>\n",
       "      <td>16.002910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Color de pelaje 3</td>\n",
       "      <td>14.736305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tama√±o</td>\n",
       "      <td>14.159547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Color de pelaje 1</td>\n",
       "      <td>11.721368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Largo de hocico</td>\n",
       "      <td>4.931495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Edad</td>\n",
       "      <td>0.969011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Sexo</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Patron de pelaje</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Color de pelaje 2</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Largo de cola</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Largo de orejas</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Tipo de orejas</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Feature Id  Importances\n",
       "0     Largo de pelaje    37.479364\n",
       "1       Color de ojos    16.002910\n",
       "2   Color de pelaje 3    14.736305\n",
       "3              Tama√±o    14.159547\n",
       "4   Color de pelaje 1    11.721368\n",
       "5     Largo de hocico     4.931495\n",
       "6                Edad     0.969011\n",
       "7                Sexo     0.000000\n",
       "8    Patron de pelaje     0.000000\n",
       "9   Color de pelaje 2     0.000000\n",
       "10      Largo de cola     0.000000\n",
       "11    Largo de orejas     0.000000\n",
       "12     Tipo de orejas     0.000000"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction1 = model.get_feature_importance(prettified=True)\n",
    "prediction1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature Id</th>\n",
       "      <th>Importances</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Largo de pelaje</td>\n",
       "      <td>31.113495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Color de ojos</td>\n",
       "      <td>19.111838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Color de pelaje 3</td>\n",
       "      <td>18.343051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tama√±o</td>\n",
       "      <td>15.203147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Color de pelaje 1</td>\n",
       "      <td>13.274599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Largo de hocico</td>\n",
       "      <td>2.468770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Edad</td>\n",
       "      <td>0.485100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Sexo</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Patron de pelaje</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Color de pelaje 2</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Largo de cola</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Largo de orejas</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Tipo de orejas</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Feature Id  Importances\n",
       "0     Largo de pelaje    31.113495\n",
       "1       Color de ojos    19.111838\n",
       "2   Color de pelaje 3    18.343051\n",
       "3              Tama√±o    15.203147\n",
       "4   Color de pelaje 1    13.274599\n",
       "5     Largo de hocico     2.468770\n",
       "6                Edad     0.485100\n",
       "7                Sexo     0.000000\n",
       "8    Patron de pelaje     0.000000\n",
       "9   Color de pelaje 2     0.000000\n",
       "10      Largo de cola     0.000000\n",
       "11    Largo de orejas     0.000000\n",
       "12     Tipo de orejas     0.000000"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction2 = model2.get_feature_importance(prettified=True)\n",
    "prediction2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature Id</th>\n",
       "      <th>Importances</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Largo de pelaje</td>\n",
       "      <td>31.113495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Color de ojos</td>\n",
       "      <td>19.111838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Color de pelaje 3</td>\n",
       "      <td>18.343051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tama√±o</td>\n",
       "      <td>15.203147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Color de pelaje 1</td>\n",
       "      <td>13.274599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Largo de hocico</td>\n",
       "      <td>2.468770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Edad</td>\n",
       "      <td>0.485100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Sexo</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Patron de pelaje</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Color de pelaje 2</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Largo de cola</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Largo de orejas</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Tipo de orejas</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Feature Id  Importances\n",
       "0     Largo de pelaje    31.113495\n",
       "1       Color de ojos    19.111838\n",
       "2   Color de pelaje 3    18.343051\n",
       "3              Tama√±o    15.203147\n",
       "4   Color de pelaje 1    13.274599\n",
       "5     Largo de hocico     2.468770\n",
       "6                Edad     0.485100\n",
       "7                Sexo     0.000000\n",
       "8    Patron de pelaje     0.000000\n",
       "9   Color de pelaje 2     0.000000\n",
       "10      Largo de cola     0.000000\n",
       "11    Largo de orejas     0.000000\n",
       "12     Tipo de orejas     0.000000"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction3 = model2.get_feature_importance(prettified=True)\n",
    "prediction3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y = train_df.Mascota\n",
    "test_df = train_df.drop('Mascota', axis=1)\n",
    "\n",
    "test_df.fillna(\"NaN\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1401]\n",
      " [1157]\n",
      " [  13]\n",
      " [1157]\n",
      " [   5]\n",
      " [1074]\n",
      " [1401]\n",
      " [  34]\n",
      " [1074]\n",
      " [3914]\n",
      " [1157]\n",
      " [6040]\n",
      " [  13]\n",
      " [  13]\n",
      " [  34]\n",
      " [  16]\n",
      " [1074]\n",
      " [1279]\n",
      " [6040]\n",
      " [3507]\n",
      " [3507]\n",
      " [6040]\n",
      " [  34]\n",
      " [  34]\n",
      " [4512]\n",
      " [  34]\n",
      " [1526]\n",
      " [1279]\n",
      " [6066]\n",
      " [  34]\n",
      " [  38]\n",
      " [1800]\n",
      " [  16]\n",
      " [  34]\n",
      " [1157]\n",
      " [6065]\n",
      " [  13]\n",
      " [1526]\n",
      " [  39]\n",
      " [  34]\n",
      " [1157]\n",
      " [4512]\n",
      " [  13]\n",
      " [1526]\n",
      " [1074]\n",
      " [1074]\n",
      " [4512]\n",
      " [1279]\n",
      " [3507]\n",
      " [  34]\n",
      " [1074]\n",
      " [4243]\n",
      " [1157]\n",
      " [4537]\n",
      " [1401]\n",
      " [4512]\n",
      " [1183]\n",
      " [  13]\n",
      " [6065]\n",
      " [1800]\n",
      " [1074]\n",
      " [4512]\n",
      " [4512]\n",
      " [6065]\n",
      " [1800]\n",
      " [1279]\n",
      " [1401]\n",
      " [3507]\n",
      " [1036]\n",
      " [1074]\n",
      " [6066]\n",
      " [1401]\n",
      " [6065]\n",
      " [1800]\n",
      " [1401]\n",
      " [4512]\n",
      " [1066]\n",
      " [4537]\n",
      " [4512]\n",
      " [4512]\n",
      " [  34]\n",
      " [1074]\n",
      " [  34]\n",
      " [  34]\n",
      " [1157]\n",
      " [6072]\n",
      " [1279]\n",
      " [1401]\n",
      " [3507]\n",
      " [3507]\n",
      " [1401]\n",
      " [6066]\n",
      " [6066]\n",
      " [3507]\n",
      " [3524]\n",
      " [  34]\n",
      " [3524]\n",
      " [  34]\n",
      " [  34]\n",
      " [6040]\n",
      " [  34]\n",
      " [3507]\n",
      " [3592]\n",
      " [6066]\n",
      " [3595]\n",
      " [1157]\n",
      " [6066]\n",
      " [3524]\n",
      " [3507]\n",
      " [4512]\n",
      " [1800]\n",
      " [4243]\n",
      " [4537]\n",
      " [1183]\n",
      " [1486]\n",
      " [1401]\n",
      " [  34]\n",
      " [1470]\n",
      " [1401]\n",
      " [1470]\n",
      " [1279]\n",
      " [1215]\n",
      " [3914]\n",
      " [1800]\n",
      " [1217]\n",
      " [6019]\n",
      " [1279]\n",
      " [3507]\n",
      " [6066]\n",
      " [3914]\n",
      " [3507]\n",
      " [1279]\n",
      " [1279]\n",
      " [1279]\n",
      " [1902]\n",
      " [4512]\n",
      " [  16]\n",
      " [1183]\n",
      " [1652]\n",
      " [4512]\n",
      " [  34]\n",
      " [1238]\n",
      " [4512]\n",
      " [1279]\n",
      " [1509]\n",
      " [4537]\n",
      " [  34]\n",
      " [1279]\n",
      " [4512]\n",
      " [1401]\n",
      " [1800]\n",
      " [1640]\n",
      " [3524]\n",
      " [1074]\n",
      " [1640]\n",
      " [1509]\n",
      " [  16]\n",
      " [4512]\n",
      " [1401]\n",
      " [3914]\n",
      " [6066]\n",
      " [4229]\n",
      " [1401]\n",
      " [3914]\n",
      " [4537]\n",
      " [3507]\n",
      " [4512]\n",
      " [  13]\n",
      " [1401]\n",
      " [4537]\n",
      " [3524]\n",
      " [4512]\n",
      " [1800]\n",
      " [6065]\n",
      " [1279]\n",
      " [1279]\n",
      " [1066]\n",
      " [3524]\n",
      " [6065]\n",
      " [3507]\n",
      " [1401]\n",
      " [6065]\n",
      " [6017]\n",
      " [4537]\n",
      " [6065]\n",
      " [6066]\n",
      " [  16]\n",
      " [3524]\n",
      " [6019]\n",
      " [1401]\n",
      " [1183]\n",
      " [1036]\n",
      " [  16]\n",
      " [6065]\n",
      " [1468]\n",
      " [3507]\n",
      " [4537]\n",
      " [1036]\n",
      " [1470]\n",
      " [  34]\n",
      " [1640]\n",
      " [3524]\n",
      " [   5]\n",
      " [1074]\n",
      " [6040]\n",
      " [1217]\n",
      " [6066]\n",
      " [3914]\n",
      " [1486]\n",
      " [1279]\n",
      " [3507]\n",
      " [4512]\n",
      " [  16]\n",
      " [6066]\n",
      " [1401]\n",
      " [4243]\n",
      " [6040]\n",
      " [4512]\n",
      " [1526]\n",
      " [3507]\n",
      " [1215]\n",
      " [1509]\n",
      " [   5]\n",
      " [1509]\n",
      " [1157]\n",
      " [1401]\n",
      " [4537]\n",
      " [4537]\n",
      " [3914]\n",
      " [3914]\n",
      " [1401]\n",
      " [1401]\n",
      " [1526]\n",
      " [1401]\n",
      " [1279]\n",
      " [4512]\n",
      " [1401]\n",
      " [1074]\n",
      " [1401]\n",
      " [3507]\n",
      " [6066]\n",
      " [6066]\n",
      " [3507]\n",
      " [1546]\n",
      " [1401]\n",
      " [4243]\n",
      " [4229]\n",
      " [6019]\n",
      " [4537]\n",
      " [1526]\n",
      " [6066]\n",
      " [1640]\n",
      " [6066]\n",
      " [6065]\n",
      " [4512]\n",
      " [3507]\n",
      " [6066]\n",
      " [1279]\n",
      " [1279]\n",
      " [6066]\n",
      " [6066]\n",
      " [4512]\n",
      " [1596]\n",
      " [1640]\n",
      " [1800]\n",
      " [4537]\n",
      " [1800]\n",
      " [4512]\n",
      " [  34]\n",
      " [1640]\n",
      " [4537]\n",
      " [4243]\n",
      " [3524]\n",
      " [1549]\n",
      " [3524]\n",
      " [4537]\n",
      " [4537]\n",
      " [1401]\n",
      " [4537]\n",
      " [6066]\n",
      " [4537]\n",
      " [6066]\n",
      " [3524]\n",
      " [1470]\n",
      " [  13]\n",
      " [1074]\n",
      " [1470]\n",
      " [1401]\n",
      " [1800]\n",
      " [4243]\n",
      " [1470]\n",
      " [1074]\n",
      " [1470]\n",
      " [6040]\n",
      " [3507]\n",
      " [4512]\n",
      " [6066]\n",
      " [1526]\n",
      " [1401]\n",
      " [1800]\n",
      " [1801]\n",
      " [3524]\n",
      " [1821]\n",
      " [4512]\n",
      " [6065]\n",
      " [6040]\n",
      " [6066]\n",
      " [1800]\n",
      " [4537]\n",
      " [3507]\n",
      " [3914]\n",
      " [  16]\n",
      " [1036]\n",
      " [1183]\n",
      " [1526]\n",
      " [3507]\n",
      " [1546]\n",
      " [  13]\n",
      " [  16]\n",
      " [1470]]\n"
     ]
    }
   ],
   "source": [
    "# print(model.predict_proba(test_df))\n",
    "print(model2.predict(test_df))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
