{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas\n",
    "from catboost import CatBoostClassifier, Pool, metrics, cv\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def load_data():\n",
    "train_df = pandas.read_csv('data/perros_train_v3.csv')\n",
    "train_df\n",
    "\n",
    "test_df = pandas.read_csv('data/perros_predict_v3.csv')\n",
    "# test_df.head()\n",
    "\n",
    "# load_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train_df.Mascota\n",
    "X = train_df.drop('Mascota', axis=1)\n",
    "\n",
    "X.fillna(\"NaN\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n"
     ]
    }
   ],
   "source": [
    "cat_features = list(range(0, X.shape[1]))\n",
    "print(cat_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels: {1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 4191, 4194, 4210, 4229, 4230, 4235, 4240, 4243, 4102, 4272, 4274, 4107, 4282, 4299, 4303, 4307, 4338, 4340, 4341, 4350, 4352, 4353, 4354, 4385, 4390, 4391, 4393, 4397, 4400, 4401, 4404, 4407, 4411, 4413, 4416, 4427, 4434, 4436, 4437, 4464, 4465, 4466, 4467, 4468, 4473, 4478, 4480, 4491, 4492, 4502, 4512, 4515, 4516, 4531, 4535, 4537, 4539, 4541, 4546, 4547, 4551, 4642, 1000, 1002, 1003, 1007, 1009, 1010, 1014, 1018, 1036, 1048, 1053, 1066, 1067, 1074, 1081, 1082, 1083, 1095, 1100, 1116, 1121, 1122, 1129, 1136, 1144, 1157, 1166, 1174, 1183, 1186, 1191, 1207, 1215, 1217, 1219, 1223, 1224, 1227, 1232, 1235, 1238, 1279, 1329, 1343, 1360, 1372, 1373, 1377, 1381, 1382, 1385, 1387, 1395, 1399, 1401, 1409, 1431, 1432, 1434, 3485, 1444, 3500, 1452, 3505, 3507, 1460, 3512, 1468, 1470, 3524, 1476, 1477, 3528, 3530, 1486, 1495, 1498, 1508, 1509, 1516, 1525, 1526, 1529, 1531, 3592, 1546, 3595, 1549, 3601, 1564, 3631, 1593, 1596, 1640, 1652, 3701, 1682, 1693, 1701, 1702, 3752, 1706, 1722, 1730, 3780, 1732, 1737, 3788, 3789, 3793, 3809, 1761, 1766, 1767, 1776, 1782, 1789, 3848, 1800, 1801, 1807, 1821, 1837, 1838, 1849, 1851, 3907, 3910, 1863, 3913, 3914, 3917, 1872, 1874, 3923, 3931, 1884, 3933, 1886, 3950, 1902, 6000, 1906, 6004, 1908, 1910, 6007, 3961, 6010, 6012, 1919, 6016, 6017, 6019, 6020, 6022, 6025, 6026, 6027, 6028, 6030, 1940, 6038, 6040, 6041, 6042, 6045, 6046, 6047, 1950, 6049, 1954, 6051, 6055, 6064, 6065, 6066, 6067, 6070, 6072, 6073, 4026, 6075, 6078, 6079, 4053, 4073, 4077}\n",
      "Zero count = -787182, One count = 787502\n"
     ]
    }
   ],
   "source": [
    "print('Labels: {}'.format(set(y)))\n",
    "print('Zero count = {}, One count = {}'.format(len(y) - sum(y), sum(y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape\n",
      "dataset 3:(320, 13)\n",
      "\n",
      "\n",
      "Column names\n",
      "\n",
      "dataset 3:\n",
      "['Edad', 'Tama√±o', 'Sexo', 'Patron de pelaje', 'Color de pelaje 1', 'Color de pelaje 2', 'Color de pelaje 3', 'Largo de pelaje', 'Color de ojos', 'Largo de hocico', 'Largo de cola', 'Largo de orejas', 'Tipo de orejas']\n"
     ]
    }
   ],
   "source": [
    "pool3 = Pool(data=X, cat_features=cat_features)\n",
    "\n",
    "print('Dataset shape')\n",
    "print('dataset 3:' + str(pool3.shape))\n",
    "\n",
    "print('\\n')\n",
    "print('Column names')\n",
    "print('\\ndataset 3:')\n",
    "print(pool3.get_feature_names())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_validation, y_train, y_validation = train_test_split(\n",
    "    X, y, train_size=0.8, random_state=1234)\n",
    "\n",
    "\n",
    "validation_df = pandas.read_csv('data/perros_test_v3.csv')\n",
    "y_validation = train_df.Mascota\n",
    "X_validation = train_df.drop('Mascota', axis=1)\n",
    "X_validation.fillna(\"NaN\", inplace=True)\n",
    "\n",
    "X_train = X\n",
    "y_train = y\n",
    "# X_validation = \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Custom logger is already specified. Specify more than one logger at same time is not thread safe."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.217853\n",
      "0:\tlearn: 5.7574177\ttest: 5.7684511\tbest: 5.7684511 (0)\ttotal: 6.21s\tremaining: 15m 25s\n",
      "1:\tlearn: 5.7142885\ttest: 5.7637918\tbest: 5.7637918 (1)\ttotal: 12.9s\tremaining: 15m 51s\n",
      "2:\tlearn: 5.6948846\ttest: 5.7643704\tbest: 5.7637918 (1)\ttotal: 19.3s\tremaining: 15m 45s\n",
      "3:\tlearn: 5.6606277\ttest: 5.7541634\tbest: 5.7541634 (3)\ttotal: 25.4s\tremaining: 15m 28s\n",
      "4:\tlearn: 5.6523862\ttest: 5.7546193\tbest: 5.7541634 (3)\ttotal: 31.5s\tremaining: 15m 13s\n",
      "5:\tlearn: 5.6305975\ttest: 5.7493117\tbest: 5.7493117 (5)\ttotal: 37.6s\tremaining: 15m 1s\n",
      "6:\tlearn: 5.5922874\ttest: 5.7397926\tbest: 5.7397926 (6)\ttotal: 43.6s\tremaining: 14m 50s\n",
      "7:\tlearn: 5.5828868\ttest: 5.7396773\tbest: 5.7396773 (7)\ttotal: 49.4s\tremaining: 14m 36s\n",
      "8:\tlearn: 5.5665959\ttest: 5.7373598\tbest: 5.7373598 (8)\ttotal: 55.2s\tremaining: 14m 24s\n",
      "9:\tlearn: 5.5375932\ttest: 5.7328063\tbest: 5.7328063 (9)\ttotal: 1m\tremaining: 14m 13s\n",
      "10:\tlearn: 5.5139868\ttest: 5.7306914\tbest: 5.7306914 (10)\ttotal: 1m 6s\tremaining: 14m 4s\n",
      "11:\tlearn: 5.4897113\ttest: 5.7218032\tbest: 5.7218032 (11)\ttotal: 1m 12s\tremaining: 13m 59s\n",
      "12:\tlearn: 5.4648690\ttest: 5.7079044\tbest: 5.7079044 (12)\ttotal: 1m 19s\tremaining: 13m 56s\n",
      "13:\tlearn: 5.4238637\ttest: 5.6983139\tbest: 5.6983139 (13)\ttotal: 1m 25s\tremaining: 13m 49s\n",
      "14:\tlearn: 5.4173287\ttest: 5.6986992\tbest: 5.6983139 (13)\ttotal: 1m 31s\tremaining: 13m 41s\n",
      "15:\tlearn: 5.3865847\ttest: 5.6923372\tbest: 5.6923372 (15)\ttotal: 1m 37s\tremaining: 13m 32s\n",
      "16:\tlearn: 5.3712748\ttest: 5.6840727\tbest: 5.6840727 (16)\ttotal: 1m 42s\tremaining: 13m 24s\n",
      "17:\tlearn: 5.3552042\ttest: 5.6851071\tbest: 5.6840727 (16)\ttotal: 1m 48s\tremaining: 13m 16s\n",
      "18:\tlearn: 5.3389824\ttest: 5.6807032\tbest: 5.6807032 (18)\ttotal: 1m 54s\tremaining: 13m 11s\n",
      "19:\tlearn: 5.3098638\ttest: 5.6732011\tbest: 5.6732011 (19)\ttotal: 2m\tremaining: 13m 4s\n",
      "20:\tlearn: 5.2775233\ttest: 5.6546839\tbest: 5.6546839 (20)\ttotal: 2m 6s\tremaining: 12m 59s\n",
      "21:\tlearn: 5.2673185\ttest: 5.6554551\tbest: 5.6546839 (20)\ttotal: 2m 12s\tremaining: 12m 53s\n",
      "22:\tlearn: 5.2243053\ttest: 5.6350481\tbest: 5.6350481 (22)\ttotal: 2m 19s\tremaining: 12m 48s\n",
      "23:\tlearn: 5.2123863\ttest: 5.6316704\tbest: 5.6316704 (23)\ttotal: 2m 25s\tremaining: 12m 42s\n",
      "24:\tlearn: 5.1872292\ttest: 5.6268708\tbest: 5.6268708 (24)\ttotal: 2m 31s\tremaining: 12m 36s\n",
      "25:\tlearn: 5.1610953\ttest: 5.6189617\tbest: 5.6189617 (25)\ttotal: 2m 37s\tremaining: 12m 30s\n",
      "26:\tlearn: 5.1484177\ttest: 5.6155974\tbest: 5.6155974 (26)\ttotal: 2m 43s\tremaining: 12m 24s\n",
      "27:\tlearn: 5.1257368\ttest: 5.6146910\tbest: 5.6146910 (27)\ttotal: 2m 49s\tremaining: 12m 18s\n",
      "28:\tlearn: 5.1180268\ttest: 5.6147203\tbest: 5.6146910 (27)\ttotal: 2m 55s\tremaining: 12m 11s\n",
      "29:\tlearn: 5.0916912\ttest: 5.6067736\tbest: 5.6067736 (29)\ttotal: 3m 1s\tremaining: 12m 5s\n",
      "30:\tlearn: 5.0819865\ttest: 5.6060322\tbest: 5.6060322 (30)\ttotal: 3m 7s\tremaining: 11m 59s\n",
      "31:\tlearn: 5.0755377\ttest: 5.6057793\tbest: 5.6057793 (31)\ttotal: 3m 13s\tremaining: 11m 54s\n",
      "32:\tlearn: 5.0689729\ttest: 5.6022425\tbest: 5.6022425 (32)\ttotal: 3m 20s\tremaining: 11m 49s\n",
      "33:\tlearn: 5.0639532\ttest: 5.5999406\tbest: 5.5999406 (33)\ttotal: 3m 26s\tremaining: 11m 43s\n",
      "34:\tlearn: 5.0172043\ttest: 5.5874770\tbest: 5.5874770 (34)\ttotal: 3m 32s\tremaining: 11m 37s\n",
      "35:\tlearn: 4.9935274\ttest: 5.5851930\tbest: 5.5851930 (35)\ttotal: 3m 38s\tremaining: 11m 31s\n",
      "36:\tlearn: 4.9747390\ttest: 5.5730462\tbest: 5.5730462 (36)\ttotal: 3m 44s\tremaining: 11m 25s\n",
      "37:\tlearn: 4.9444304\ttest: 5.5628023\tbest: 5.5628023 (37)\ttotal: 3m 50s\tremaining: 11m 19s\n",
      "38:\tlearn: 4.9292072\ttest: 5.5618942\tbest: 5.5618942 (38)\ttotal: 3m 56s\tremaining: 11m 13s\n",
      "39:\tlearn: 4.8737570\ttest: 5.5506634\tbest: 5.5506634 (39)\ttotal: 4m 3s\tremaining: 11m 9s\n",
      "40:\tlearn: 4.8596021\ttest: 5.5509375\tbest: 5.5506634 (39)\ttotal: 4m 11s\tremaining: 11m 8s\n",
      "41:\tlearn: 4.8322926\ttest: 5.5506907\tbest: 5.5506634 (39)\ttotal: 4m 20s\tremaining: 11m 9s\n",
      "42:\tlearn: 4.8263072\ttest: 5.5487329\tbest: 5.5487329 (42)\ttotal: 4m 28s\tremaining: 11m 7s\n",
      "43:\tlearn: 4.8136334\ttest: 5.5494591\tbest: 5.5487329 (42)\ttotal: 4m 34s\tremaining: 11m 1s\n",
      "44:\tlearn: 4.7824425\ttest: 5.5384615\tbest: 5.5384615 (44)\ttotal: 4m 41s\tremaining: 10m 56s\n",
      "45:\tlearn: 4.7510971\ttest: 5.5393146\tbest: 5.5384615 (44)\ttotal: 4m 46s\tremaining: 10m 48s\n",
      "46:\tlearn: 4.7393163\ttest: 5.5302593\tbest: 5.5302593 (46)\ttotal: 4m 52s\tremaining: 10m 41s\n",
      "47:\tlearn: 4.7122187\ttest: 5.5306679\tbest: 5.5302593 (46)\ttotal: 4m 58s\tremaining: 10m 33s\n",
      "48:\tlearn: 4.7064794\ttest: 5.5290674\tbest: 5.5290674 (48)\ttotal: 5m 3s\tremaining: 10m 26s\n",
      "49:\tlearn: 4.7050915\ttest: 5.5279851\tbest: 5.5279851 (49)\ttotal: 5m 9s\tremaining: 10m 19s\n",
      "50:\tlearn: 4.6789827\ttest: 5.5282668\tbest: 5.5279851 (49)\ttotal: 5m 14s\tremaining: 10m 11s\n",
      "51:\tlearn: 4.6694181\ttest: 5.5250367\tbest: 5.5250367 (51)\ttotal: 5m 20s\tremaining: 10m 4s\n",
      "52:\tlearn: 4.6422222\ttest: 5.5263630\tbest: 5.5250367 (51)\ttotal: 5m 29s\tremaining: 10m 2s\n",
      "53:\tlearn: 4.6333019\ttest: 5.5268861\tbest: 5.5250367 (51)\ttotal: 5m 37s\tremaining: 9m 59s\n",
      "54:\tlearn: 4.6073613\ttest: 5.5276347\tbest: 5.5250367 (51)\ttotal: 5m 44s\tremaining: 9m 55s\n",
      "55:\tlearn: 4.5992952\ttest: 5.5278347\tbest: 5.5250367 (51)\ttotal: 5m 51s\tremaining: 9m 49s\n",
      "56:\tlearn: 4.5983790\ttest: 5.5267911\tbest: 5.5250367 (51)\ttotal: 5m 57s\tremaining: 9m 43s\n",
      "57:\tlearn: 4.5875865\ttest: 5.5273752\tbest: 5.5250367 (51)\ttotal: 6m 3s\tremaining: 9m 36s\n",
      "58:\tlearn: 4.5562911\ttest: 5.5018668\tbest: 5.5018668 (58)\ttotal: 6m 9s\tremaining: 9m 29s\n",
      "59:\tlearn: 4.5402038\ttest: 5.4972495\tbest: 5.4972495 (59)\ttotal: 6m 17s\tremaining: 9m 25s\n",
      "60:\tlearn: 4.5249391\ttest: 5.4939123\tbest: 5.4939123 (60)\ttotal: 6m 24s\tremaining: 9m 21s\n",
      "61:\tlearn: 4.5182479\ttest: 5.4934782\tbest: 5.4934782 (61)\ttotal: 6m 32s\tremaining: 9m 17s\n",
      "62:\tlearn: 4.5045334\ttest: 5.4943709\tbest: 5.4934782 (61)\ttotal: 6m 39s\tremaining: 9m 11s\n",
      "63:\tlearn: 4.4993262\ttest: 5.4944003\tbest: 5.4934782 (61)\ttotal: 6m 45s\tremaining: 9m 5s\n",
      "64:\tlearn: 4.4617905\ttest: 5.4960424\tbest: 5.4934782 (61)\ttotal: 6m 52s\tremaining: 8m 59s\n",
      "65:\tlearn: 4.4232421\ttest: 5.4961412\tbest: 5.4934782 (61)\ttotal: 6m 59s\tremaining: 8m 53s\n",
      "66:\tlearn: 4.4227381\ttest: 5.4951125\tbest: 5.4934782 (61)\ttotal: 7m 5s\tremaining: 8m 47s\n",
      "67:\tlearn: 4.3953877\ttest: 5.4975224\tbest: 5.4934782 (61)\ttotal: 7m 12s\tremaining: 8m 41s\n",
      "68:\tlearn: 4.3882276\ttest: 5.4973986\tbest: 5.4934782 (61)\ttotal: 7m 20s\tremaining: 8m 36s\n",
      "69:\tlearn: 4.3540318\ttest: 5.4780171\tbest: 5.4780171 (69)\ttotal: 7m 27s\tremaining: 8m 31s\n",
      "70:\tlearn: 4.3286469\ttest: 5.4724443\tbest: 5.4724443 (70)\ttotal: 7m 34s\tremaining: 8m 25s\n",
      "71:\tlearn: 4.3098603\ttest: 5.4709488\tbest: 5.4709488 (71)\ttotal: 7m 41s\tremaining: 8m 19s\n",
      "72:\tlearn: 4.2943287\ttest: 5.4719917\tbest: 5.4709488 (71)\ttotal: 7m 48s\tremaining: 8m 14s\n",
      "73:\tlearn: 4.2808887\ttest: 5.4662482\tbest: 5.4662482 (73)\ttotal: 7m 55s\tremaining: 8m 8s\n",
      "74:\tlearn: 4.2569259\ttest: 5.4527432\tbest: 5.4527432 (74)\ttotal: 8m 2s\tremaining: 8m 2s\n",
      "75:\tlearn: 4.2399000\ttest: 5.4537859\tbest: 5.4527432 (74)\ttotal: 8m 9s\tremaining: 7m 56s\n",
      "76:\tlearn: 4.2253688\ttest: 5.4544198\tbest: 5.4527432 (74)\ttotal: 8m 15s\tremaining: 7m 49s\n",
      "77:\tlearn: 4.2214282\ttest: 5.4517757\tbest: 5.4517757 (77)\ttotal: 8m 22s\tremaining: 7m 43s\n",
      "78:\tlearn: 4.2186810\ttest: 5.4512596\tbest: 5.4512596 (78)\ttotal: 8m 28s\tremaining: 7m 37s\n",
      "79:\tlearn: 4.2000493\ttest: 5.4512402\tbest: 5.4512402 (79)\ttotal: 8m 35s\tremaining: 7m 30s\n",
      "80:\tlearn: 4.1740904\ttest: 5.4510227\tbest: 5.4510227 (80)\ttotal: 8m 41s\tremaining: 7m 24s\n",
      "81:\tlearn: 4.1712552\ttest: 5.4503501\tbest: 5.4503501 (81)\ttotal: 8m 48s\tremaining: 7m 18s\n",
      "82:\tlearn: 4.1655715\ttest: 5.4504471\tbest: 5.4503501 (81)\ttotal: 8m 55s\tremaining: 7m 11s\n",
      "83:\tlearn: 4.1488807\ttest: 5.4522414\tbest: 5.4503501 (81)\ttotal: 9m 1s\tremaining: 7m 5s\n",
      "84:\tlearn: 4.1145426\ttest: 5.4459496\tbest: 5.4459496 (84)\ttotal: 9m 8s\tremaining: 6m 59s\n",
      "85:\tlearn: 4.0802251\ttest: 5.4473893\tbest: 5.4459496 (84)\ttotal: 9m 14s\tremaining: 6m 52s\n",
      "86:\tlearn: 4.0756168\ttest: 5.4472588\tbest: 5.4459496 (84)\ttotal: 9m 21s\tremaining: 6m 46s\n",
      "87:\tlearn: 4.0573250\ttest: 5.4379409\tbest: 5.4379409 (87)\ttotal: 9m 27s\tremaining: 6m 39s\n",
      "88:\tlearn: 4.0364660\ttest: 5.4367208\tbest: 5.4367208 (88)\ttotal: 9m 34s\tremaining: 6m 33s\n",
      "89:\tlearn: 4.0314051\ttest: 5.4367512\tbest: 5.4367208 (88)\ttotal: 9m 40s\tremaining: 6m 27s\n",
      "90:\tlearn: 3.9923520\ttest: 5.4274554\tbest: 5.4274554 (90)\ttotal: 9m 47s\tremaining: 6m 21s\n",
      "91:\tlearn: 3.9875719\ttest: 5.4276328\tbest: 5.4274554 (90)\ttotal: 9m 54s\tremaining: 6m 14s\n",
      "92:\tlearn: 3.9865075\ttest: 5.4270161\tbest: 5.4270161 (92)\ttotal: 10m\tremaining: 6m 8s\n",
      "93:\tlearn: 3.9779212\ttest: 5.4274705\tbest: 5.4270161 (92)\ttotal: 10m 7s\tremaining: 6m 1s\n",
      "94:\tlearn: 3.9635239\ttest: 5.4290119\tbest: 5.4270161 (92)\ttotal: 10m 13s\tremaining: 5m 55s\n",
      "95:\tlearn: 3.9570120\ttest: 5.4251812\tbest: 5.4251812 (95)\ttotal: 10m 20s\tremaining: 5m 48s\n",
      "96:\tlearn: 3.9474269\ttest: 5.4249965\tbest: 5.4249965 (96)\ttotal: 10m 27s\tremaining: 5m 42s\n",
      "97:\tlearn: 3.9437140\ttest: 5.4235672\tbest: 5.4235672 (97)\ttotal: 10m 34s\tremaining: 5m 36s\n",
      "98:\tlearn: 3.9399684\ttest: 5.4233708\tbest: 5.4233708 (98)\ttotal: 10m 41s\tremaining: 5m 30s\n",
      "99:\tlearn: 3.9289636\ttest: 5.4217071\tbest: 5.4217071 (99)\ttotal: 10m 47s\tremaining: 5m 23s\n",
      "100:\tlearn: 3.9271486\ttest: 5.4212514\tbest: 5.4212514 (100)\ttotal: 10m 54s\tremaining: 5m 17s\n",
      "101:\tlearn: 3.8997289\ttest: 5.4220893\tbest: 5.4212514 (100)\ttotal: 11m 1s\tremaining: 5m 11s\n",
      "102:\tlearn: 3.8882644\ttest: 5.4232368\tbest: 5.4212514 (100)\ttotal: 11m 8s\tremaining: 5m 4s\n",
      "103:\tlearn: 3.8732198\ttest: 5.4233565\tbest: 5.4212514 (100)\ttotal: 11m 14s\tremaining: 4m 58s\n",
      "104:\tlearn: 3.8438080\ttest: 5.4217245\tbest: 5.4212514 (100)\ttotal: 11m 21s\tremaining: 4m 52s\n",
      "105:\tlearn: 3.8318996\ttest: 5.4134691\tbest: 5.4134691 (105)\ttotal: 11m 28s\tremaining: 4m 45s\n",
      "106:\tlearn: 3.8248577\ttest: 5.4143104\tbest: 5.4134691 (105)\ttotal: 11m 35s\tremaining: 4m 39s\n",
      "107:\tlearn: 3.7959602\ttest: 5.4098148\tbest: 5.4098148 (107)\ttotal: 11m 41s\tremaining: 4m 32s\n",
      "108:\tlearn: 3.7915071\ttest: 5.4090564\tbest: 5.4090564 (108)\ttotal: 11m 48s\tremaining: 4m 26s\n",
      "109:\tlearn: 3.7860576\ttest: 5.4097867\tbest: 5.4090564 (108)\ttotal: 11m 54s\tremaining: 4m 19s\n",
      "110:\tlearn: 3.7761146\ttest: 5.4036105\tbest: 5.4036105 (110)\ttotal: 12m 1s\tremaining: 4m 13s\n",
      "111:\tlearn: 3.7688879\ttest: 5.4045435\tbest: 5.4036105 (110)\ttotal: 12m 7s\tremaining: 4m 6s\n",
      "112:\tlearn: 3.7319601\ttest: 5.4043176\tbest: 5.4036105 (110)\ttotal: 12m 14s\tremaining: 4m\n",
      "113:\tlearn: 3.7121538\ttest: 5.3862682\tbest: 5.3862682 (113)\ttotal: 12m 20s\tremaining: 3m 53s\n",
      "114:\tlearn: 3.6825728\ttest: 5.3880499\tbest: 5.3862682 (113)\ttotal: 12m 27s\tremaining: 3m 47s\n",
      "115:\tlearn: 3.6604428\ttest: 5.3893744\tbest: 5.3862682 (113)\ttotal: 12m 34s\tremaining: 3m 41s\n",
      "116:\tlearn: 3.6196014\ttest: 5.3764902\tbest: 5.3764902 (116)\ttotal: 12m 40s\tremaining: 3m 34s\n",
      "117:\tlearn: 3.5747099\ttest: 5.3693298\tbest: 5.3693298 (117)\ttotal: 12m 47s\tremaining: 3m 28s\n",
      "118:\tlearn: 3.5722010\ttest: 5.3692855\tbest: 5.3692855 (118)\ttotal: 12m 53s\tremaining: 3m 21s\n",
      "119:\tlearn: 3.5664003\ttest: 5.3696517\tbest: 5.3692855 (118)\ttotal: 13m\tremaining: 3m 15s\n",
      "120:\tlearn: 3.5514776\ttest: 5.3702297\tbest: 5.3692855 (118)\ttotal: 13m 6s\tremaining: 3m 8s\n",
      "121:\tlearn: 3.5406931\ttest: 5.3648774\tbest: 5.3648774 (121)\ttotal: 13m 13s\tremaining: 3m 2s\n",
      "122:\tlearn: 3.5207799\ttest: 5.3667903\tbest: 5.3648774 (121)\ttotal: 13m 19s\tremaining: 2m 55s\n",
      "123:\tlearn: 3.4990127\ttest: 5.3602821\tbest: 5.3602821 (123)\ttotal: 13m 26s\tremaining: 2m 49s\n",
      "124:\tlearn: 3.4777624\ttest: 5.3621795\tbest: 5.3602821 (123)\ttotal: 13m 32s\tremaining: 2m 42s\n",
      "125:\tlearn: 3.4683925\ttest: 5.3620986\tbest: 5.3602821 (123)\ttotal: 13m 39s\tremaining: 2m 36s\n",
      "126:\tlearn: 3.4306336\ttest: 5.3444154\tbest: 5.3444154 (126)\ttotal: 13m 45s\tremaining: 2m 29s\n",
      "127:\tlearn: 3.3982439\ttest: 5.3288318\tbest: 5.3288318 (127)\ttotal: 13m 51s\tremaining: 2m 22s\n",
      "128:\tlearn: 3.3812934\ttest: 5.3298960\tbest: 5.3288318 (127)\ttotal: 13m 57s\tremaining: 2m 16s\n",
      "129:\tlearn: 3.3798956\ttest: 5.3278323\tbest: 5.3278323 (129)\ttotal: 14m 3s\tremaining: 2m 9s\n",
      "130:\tlearn: 3.3632785\ttest: 5.3158108\tbest: 5.3158108 (130)\ttotal: 14m 9s\tremaining: 2m 3s\n",
      "131:\tlearn: 3.3364080\ttest: 5.2888041\tbest: 5.2888041 (131)\ttotal: 14m 15s\tremaining: 1m 56s\n",
      "132:\tlearn: 3.3105213\ttest: 5.2710989\tbest: 5.2710989 (132)\ttotal: 14m 21s\tremaining: 1m 50s\n",
      "133:\tlearn: 3.2922561\ttest: 5.2736673\tbest: 5.2710989 (132)\ttotal: 14m 27s\tremaining: 1m 43s\n",
      "134:\tlearn: 3.2872414\ttest: 5.2742401\tbest: 5.2710989 (132)\ttotal: 14m 33s\tremaining: 1m 37s\n",
      "135:\tlearn: 3.2612749\ttest: 5.2726495\tbest: 5.2710989 (132)\ttotal: 14m 40s\tremaining: 1m 30s\n",
      "136:\tlearn: 3.2501721\ttest: 5.2731581\tbest: 5.2710989 (132)\ttotal: 14m 46s\tremaining: 1m 24s\n",
      "137:\tlearn: 3.2436828\ttest: 5.2713815\tbest: 5.2710989 (132)\ttotal: 14m 52s\tremaining: 1m 17s\n",
      "138:\tlearn: 3.2173271\ttest: 5.2637455\tbest: 5.2637455 (138)\ttotal: 14m 58s\tremaining: 1m 11s\n",
      "139:\tlearn: 3.1976089\ttest: 5.2531429\tbest: 5.2531429 (139)\ttotal: 15m 4s\tremaining: 1m 4s\n",
      "140:\tlearn: 3.1724194\ttest: 5.2458162\tbest: 5.2458162 (140)\ttotal: 15m 11s\tremaining: 58.2s\n",
      "141:\tlearn: 3.1587379\ttest: 5.2447654\tbest: 5.2447654 (141)\ttotal: 15m 17s\tremaining: 51.7s\n",
      "142:\tlearn: 3.1568659\ttest: 5.2446083\tbest: 5.2446083 (142)\ttotal: 15m 23s\tremaining: 45.2s\n",
      "143:\tlearn: 3.1492581\ttest: 5.2451716\tbest: 5.2446083 (142)\ttotal: 15m 29s\tremaining: 38.7s\n",
      "144:\tlearn: 3.1379229\ttest: 5.2418322\tbest: 5.2418322 (144)\ttotal: 15m 36s\tremaining: 32.3s\n",
      "145:\tlearn: 3.1185848\ttest: 5.2284182\tbest: 5.2284182 (145)\ttotal: 15m 43s\tremaining: 25.8s\n",
      "146:\tlearn: 3.1094572\ttest: 5.2295913\tbest: 5.2284182 (145)\ttotal: 15m 49s\tremaining: 19.4s\n",
      "147:\tlearn: 3.0896516\ttest: 5.2267065\tbest: 5.2267065 (147)\ttotal: 15m 56s\tremaining: 12.9s\n",
      "148:\tlearn: 3.0738010\ttest: 5.2181370\tbest: 5.2181370 (148)\ttotal: 16m 2s\tremaining: 6.46s\n",
      "149:\tlearn: 3.0627903\ttest: 5.2200043\tbest: 5.2181370 (148)\ttotal: 16m 8s\tremaining: 0us\n",
      "\n",
      "bestTest = 5.218137045\n",
      "bestIteration = 148\n",
      "\n",
      "Shrink model to first 149 iterations.\n",
      "Model is fitted: True\n",
      "Model params:\n",
      "{'iterations': 150, 'depth': 3, 'loss_function': 'MultiClass', 'random_seed': 63, 'use_best_model': True}\n"
     ]
    }
   ],
   "source": [
    "''' model = CatBoostClassifier(\n",
    "    iterations=100,\n",
    "    depth=3,\n",
    "    loss_function='MultiClass'\n",
    ") '''\n",
    "model = CatBoostClassifier(\n",
    "    random_seed=63,\n",
    "    iterations=150,\n",
    "    # learning_rate=0.25,\n",
    "    depth=3,\n",
    "    loss_function='MultiClass',\n",
    "    use_best_model=True\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    X_train, y_train,\n",
    "    cat_features=cat_features,\n",
    "    eval_set=(X_validation, y_validation),\n",
    "    # verbose=False\n",
    ")\n",
    "\n",
    "print('Model is fitted: ' + str(model.is_fitted()))\n",
    "print('Model params:')\n",
    "print(model.get_params())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.217853\n",
      "0:\tlearn: 5.2046555\ttest: 5.2134757\tbest: 5.2134757 (0)\ttotal: 7.7s\tremaining: 19m 6s\n",
      "1:\tlearn: 5.1634807\ttest: 5.2120469\tbest: 5.2120469 (1)\ttotal: 14.7s\tremaining: 18m 8s\n",
      "2:\tlearn: 5.1453802\ttest: 5.2108142\tbest: 5.2108142 (2)\ttotal: 22.7s\tremaining: 18m 33s\n",
      "3:\tlearn: 5.1177736\ttest: 5.2034173\tbest: 5.2034173 (3)\ttotal: 30.6s\tremaining: 18m 35s\n",
      "4:\tlearn: 5.1065871\ttest: 5.1993662\tbest: 5.1993662 (4)\ttotal: 37.3s\tremaining: 18m 2s\n",
      "5:\tlearn: 5.0825682\ttest: 5.1950779\tbest: 5.1950779 (5)\ttotal: 43.7s\tremaining: 17m 29s\n",
      "6:\tlearn: 5.0498946\ttest: 5.1881394\tbest: 5.1881394 (6)\ttotal: 50.4s\tremaining: 17m 8s\n",
      "7:\tlearn: 5.0382427\ttest: 5.1839985\tbest: 5.1839985 (7)\ttotal: 57.6s\tremaining: 17m 2s\n",
      "8:\tlearn: 5.0219381\ttest: 5.1797768\tbest: 5.1797768 (8)\ttotal: 1m 4s\tremaining: 16m 46s\n",
      "9:\tlearn: 5.0060330\ttest: 5.1758371\tbest: 5.1758371 (9)\ttotal: 1m 10s\tremaining: 16m 33s\n",
      "10:\tlearn: 4.9822763\ttest: 5.1725216\tbest: 5.1725216 (10)\ttotal: 1m 17s\tremaining: 16m 21s\n",
      "11:\tlearn: 4.9589742\ttest: 5.1645830\tbest: 5.1645830 (11)\ttotal: 1m 24s\tremaining: 16m 9s\n",
      "12:\tlearn: 4.9365912\ttest: 5.1526281\tbest: 5.1526281 (12)\ttotal: 1m 30s\tremaining: 15m 56s\n",
      "13:\tlearn: 4.8994034\ttest: 5.1469726\tbest: 5.1469726 (13)\ttotal: 1m 37s\tremaining: 15m 44s\n",
      "14:\tlearn: 4.8911917\ttest: 5.1445671\tbest: 5.1445671 (14)\ttotal: 1m 43s\tremaining: 15m 32s\n",
      "15:\tlearn: 4.8780312\ttest: 5.1431758\tbest: 5.1431758 (15)\ttotal: 1m 50s\tremaining: 15m 23s\n",
      "16:\tlearn: 4.8636039\ttest: 5.1349912\tbest: 5.1349912 (16)\ttotal: 1m 56s\tremaining: 15m 14s\n",
      "17:\tlearn: 4.8475989\ttest: 5.1347943\tbest: 5.1347943 (17)\ttotal: 2m 3s\tremaining: 15m 4s\n",
      "18:\tlearn: 4.8324605\ttest: 5.1304498\tbest: 5.1304498 (18)\ttotal: 2m 9s\tremaining: 14m 54s\n",
      "19:\tlearn: 4.8090234\ttest: 5.1256169\tbest: 5.1256169 (19)\ttotal: 2m 16s\tremaining: 14m 46s\n",
      "20:\tlearn: 4.7782886\ttest: 5.1097165\tbest: 5.1097165 (20)\ttotal: 2m 23s\tremaining: 14m 40s\n",
      "21:\tlearn: 4.7674988\ttest: 5.1088306\tbest: 5.1088306 (21)\ttotal: 2m 29s\tremaining: 14m 31s\n",
      "22:\tlearn: 4.7284996\ttest: 5.0924775\tbest: 5.0924775 (22)\ttotal: 2m 36s\tremaining: 14m 22s\n",
      "23:\tlearn: 4.7166310\ttest: 5.0887544\tbest: 5.0887544 (23)\ttotal: 2m 42s\tremaining: 14m 12s\n",
      "24:\tlearn: 4.6933642\ttest: 5.0853282\tbest: 5.0853282 (24)\ttotal: 2m 48s\tremaining: 14m 3s\n",
      "25:\tlearn: 4.6828111\ttest: 5.0846060\tbest: 5.0846060 (25)\ttotal: 2m 55s\tremaining: 13m 54s\n",
      "26:\tlearn: 4.6705155\ttest: 5.0808026\tbest: 5.0808026 (26)\ttotal: 3m 1s\tremaining: 13m 47s\n",
      "27:\tlearn: 4.6475504\ttest: 5.0789509\tbest: 5.0789509 (27)\ttotal: 3m 7s\tremaining: 13m 38s\n",
      "28:\tlearn: 4.6392160\ttest: 5.0773403\tbest: 5.0773403 (28)\ttotal: 3m 14s\tremaining: 13m 30s\n",
      "29:\tlearn: 4.6136639\ttest: 5.0715620\tbest: 5.0715620 (29)\ttotal: 3m 20s\tremaining: 13m 22s\n",
      "30:\tlearn: 4.6036036\ttest: 5.0694543\tbest: 5.0694543 (30)\ttotal: 3m 27s\tremaining: 13m 14s\n",
      "31:\tlearn: 4.5967756\ttest: 5.0682176\tbest: 5.0682176 (31)\ttotal: 3m 33s\tremaining: 13m 7s\n",
      "32:\tlearn: 4.5898014\ttest: 5.0639185\tbest: 5.0639185 (32)\ttotal: 3m 39s\tremaining: 12m 59s\n",
      "33:\tlearn: 4.5559976\ttest: 5.0502940\tbest: 5.0502940 (33)\ttotal: 3m 46s\tremaining: 12m 52s\n",
      "34:\tlearn: 4.5124951\ttest: 5.0457295\tbest: 5.0457295 (34)\ttotal: 3m 52s\tremaining: 12m 44s\n",
      "35:\tlearn: 4.4851697\ttest: 5.0452129\tbest: 5.0452129 (35)\ttotal: 3m 58s\tremaining: 12m 36s\n",
      "36:\tlearn: 4.4388117\ttest: 5.0354930\tbest: 5.0354930 (36)\ttotal: 4m 5s\tremaining: 12m 29s\n",
      "37:\tlearn: 4.4348559\ttest: 5.0333679\tbest: 5.0333679 (37)\ttotal: 4m 11s\tremaining: 12m 21s\n",
      "38:\tlearn: 4.4227934\ttest: 5.0322522\tbest: 5.0322522 (38)\ttotal: 4m 17s\tremaining: 12m 14s\n",
      "39:\tlearn: 4.4209210\ttest: 5.0298734\tbest: 5.0298734 (39)\ttotal: 4m 24s\tremaining: 12m 7s\n",
      "40:\tlearn: 4.4058922\ttest: 5.0290402\tbest: 5.0290402 (40)\ttotal: 4m 30s\tremaining: 12m\n",
      "41:\tlearn: 4.3835425\ttest: 5.0286113\tbest: 5.0286113 (41)\ttotal: 4m 37s\tremaining: 11m 52s\n",
      "42:\tlearn: 4.3687223\ttest: 5.0256684\tbest: 5.0256684 (42)\ttotal: 4m 43s\tremaining: 11m 45s\n",
      "43:\tlearn: 4.3584767\ttest: 5.0256141\tbest: 5.0256141 (43)\ttotal: 4m 49s\tremaining: 11m 38s\n",
      "44:\tlearn: 4.3490135\ttest: 5.0232803\tbest: 5.0232803 (44)\ttotal: 4m 56s\tremaining: 11m 31s\n",
      "45:\tlearn: 4.3209862\ttest: 5.0092023\tbest: 5.0092023 (45)\ttotal: 5m 2s\tremaining: 11m 23s\n",
      "46:\tlearn: 4.2992015\ttest: 4.9970456\tbest: 4.9970456 (46)\ttotal: 5m 8s\tremaining: 11m 16s\n",
      "47:\tlearn: 4.2750004\ttest: 4.9872275\tbest: 4.9872275 (47)\ttotal: 5m 15s\tremaining: 11m 9s\n",
      "48:\tlearn: 4.2435843\ttest: 4.9836113\tbest: 4.9836113 (48)\ttotal: 5m 21s\tremaining: 11m 2s\n",
      "49:\tlearn: 4.2188443\ttest: 4.9798794\tbest: 4.9798794 (49)\ttotal: 5m 28s\tremaining: 10m 56s\n",
      "50:\tlearn: 4.2149353\ttest: 4.9783299\tbest: 4.9783299 (50)\ttotal: 5m 34s\tremaining: 10m 49s\n",
      "51:\tlearn: 4.2060491\ttest: 4.9777186\tbest: 4.9777186 (51)\ttotal: 5m 40s\tremaining: 10m 41s\n",
      "52:\tlearn: 4.1797552\ttest: 4.9780670\tbest: 4.9777186 (51)\ttotal: 5m 46s\tremaining: 10m 34s\n",
      "53:\tlearn: 4.1444345\ttest: 4.9796466\tbest: 4.9777186 (51)\ttotal: 5m 53s\tremaining: 10m 28s\n",
      "54:\tlearn: 4.1426042\ttest: 4.9779021\tbest: 4.9777186 (51)\ttotal: 5m 59s\tremaining: 10m 21s\n",
      "55:\tlearn: 4.1392562\ttest: 4.9767141\tbest: 4.9767141 (55)\ttotal: 6m 5s\tremaining: 10m 14s\n",
      "56:\tlearn: 4.1191118\ttest: 4.9656533\tbest: 4.9656533 (56)\ttotal: 6m 12s\tremaining: 10m 7s\n",
      "57:\tlearn: 4.1141388\ttest: 4.9650584\tbest: 4.9650584 (57)\ttotal: 6m 18s\tremaining: 10m\n",
      "58:\tlearn: 4.1114185\ttest: 4.9627444\tbest: 4.9627444 (58)\ttotal: 6m 24s\tremaining: 9m 53s\n",
      "59:\tlearn: 4.0961834\ttest: 4.9630652\tbest: 4.9627444 (58)\ttotal: 6m 31s\tremaining: 9m 47s\n",
      "60:\tlearn: 4.0824285\ttest: 4.9614635\tbest: 4.9614635 (60)\ttotal: 6m 38s\tremaining: 9m 40s\n",
      "61:\tlearn: 4.0757769\ttest: 4.9608610\tbest: 4.9608610 (61)\ttotal: 6m 44s\tremaining: 9m 34s\n",
      "62:\tlearn: 4.0599965\ttest: 4.9619452\tbest: 4.9608610 (61)\ttotal: 6m 51s\tremaining: 9m 27s\n",
      "63:\tlearn: 4.0549039\ttest: 4.9614556\tbest: 4.9608610 (61)\ttotal: 6m 57s\tremaining: 9m 20s\n",
      "64:\tlearn: 4.0137626\ttest: 4.9627482\tbest: 4.9608610 (61)\ttotal: 7m 3s\tremaining: 9m 14s\n",
      "65:\tlearn: 3.9758711\ttest: 4.9629093\tbest: 4.9608610 (61)\ttotal: 7m 10s\tremaining: 9m 7s\n",
      "66:\tlearn: 3.9750766\ttest: 4.9616138\tbest: 4.9608610 (61)\ttotal: 7m 16s\tremaining: 9m 1s\n",
      "67:\tlearn: 3.9514270\ttest: 4.9581325\tbest: 4.9581325 (67)\ttotal: 7m 23s\tremaining: 8m 54s\n",
      "68:\tlearn: 3.9482757\ttest: 4.9576537\tbest: 4.9576537 (68)\ttotal: 7m 29s\tremaining: 8m 48s\n",
      "69:\tlearn: 3.9427487\ttest: 4.9561654\tbest: 4.9561654 (69)\ttotal: 7m 36s\tremaining: 8m 41s\n",
      "70:\tlearn: 3.9061534\ttest: 4.9578708\tbest: 4.9561654 (69)\ttotal: 7m 42s\tremaining: 8m 35s\n",
      "71:\tlearn: 3.8905955\ttest: 4.9570273\tbest: 4.9561654 (69)\ttotal: 7m 49s\tremaining: 8m 28s\n",
      "72:\tlearn: 3.8719830\ttest: 4.9580934\tbest: 4.9561654 (69)\ttotal: 7m 55s\tremaining: 8m 21s\n",
      "73:\tlearn: 3.8595488\ttest: 4.9541257\tbest: 4.9541257 (73)\ttotal: 8m 2s\tremaining: 8m 15s\n",
      "74:\tlearn: 3.8390899\ttest: 4.9446002\tbest: 4.9446002 (74)\ttotal: 8m 8s\tremaining: 8m 8s\n",
      "75:\tlearn: 3.8226235\ttest: 4.9456821\tbest: 4.9446002 (74)\ttotal: 8m 15s\tremaining: 8m 2s\n",
      "76:\tlearn: 3.8047423\ttest: 4.9466770\tbest: 4.9446002 (74)\ttotal: 8m 21s\tremaining: 7m 55s\n",
      "77:\tlearn: 3.8010171\ttest: 4.9443472\tbest: 4.9443472 (77)\ttotal: 8m 27s\tremaining: 7m 48s\n",
      "78:\tlearn: 3.7860190\ttest: 4.9443963\tbest: 4.9443472 (77)\ttotal: 8m 34s\tremaining: 7m 42s\n",
      "79:\tlearn: 3.7688362\ttest: 4.9451578\tbest: 4.9443472 (77)\ttotal: 8m 40s\tremaining: 7m 35s\n",
      "80:\tlearn: 3.7453467\ttest: 4.9460815\tbest: 4.9443472 (77)\ttotal: 8m 46s\tremaining: 7m 28s\n",
      "81:\tlearn: 3.7427287\ttest: 4.9451753\tbest: 4.9443472 (77)\ttotal: 8m 53s\tremaining: 7m 22s\n",
      "82:\tlearn: 3.7372206\ttest: 4.9451469\tbest: 4.9443472 (77)\ttotal: 8m 59s\tremaining: 7m 15s\n",
      "83:\tlearn: 3.7219235\ttest: 4.9462311\tbest: 4.9443472 (77)\ttotal: 9m 5s\tremaining: 7m 8s\n",
      "84:\tlearn: 3.6875060\ttest: 4.9490521\tbest: 4.9443472 (77)\ttotal: 9m 11s\tremaining: 7m 1s\n",
      "85:\tlearn: 3.6534286\ttest: 4.9496105\tbest: 4.9443472 (77)\ttotal: 9m 17s\tremaining: 6m 55s\n",
      "86:\tlearn: 3.6493211\ttest: 4.9494884\tbest: 4.9443472 (77)\ttotal: 9m 24s\tremaining: 6m 48s\n",
      "87:\tlearn: 3.6354963\ttest: 4.9499102\tbest: 4.9443472 (77)\ttotal: 9m 30s\tremaining: 6m 41s\n",
      "88:\tlearn: 3.6224996\ttest: 4.9506562\tbest: 4.9443472 (77)\ttotal: 9m 36s\tremaining: 6m 35s\n",
      "89:\tlearn: 3.6038686\ttest: 4.9398645\tbest: 4.9398645 (89)\ttotal: 9m 43s\tremaining: 6m 28s\n",
      "90:\tlearn: 3.5895587\ttest: 4.9407963\tbest: 4.9398645 (89)\ttotal: 9m 49s\tremaining: 6m 22s\n",
      "91:\tlearn: 3.5674930\ttest: 4.9355962\tbest: 4.9355962 (91)\ttotal: 9m 55s\tremaining: 6m 15s\n",
      "92:\tlearn: 3.5273570\ttest: 4.9289909\tbest: 4.9289909 (92)\ttotal: 10m 1s\tremaining: 6m 8s\n",
      "93:\tlearn: 3.5224432\ttest: 4.9288108\tbest: 4.9288108 (93)\ttotal: 10m 8s\tremaining: 6m 2s\n",
      "94:\tlearn: 3.5180391\ttest: 4.9285664\tbest: 4.9285664 (94)\ttotal: 10m 14s\tremaining: 5m 55s\n",
      "95:\tlearn: 3.4742475\ttest: 4.9308729\tbest: 4.9285664 (94)\ttotal: 10m 20s\tremaining: 5m 49s\n",
      "96:\tlearn: 3.4351444\ttest: 4.9256318\tbest: 4.9256318 (96)\ttotal: 10m 26s\tremaining: 5m 42s\n",
      "97:\tlearn: 3.4278030\ttest: 4.9230686\tbest: 4.9230686 (97)\ttotal: 10m 33s\tremaining: 5m 36s\n",
      "98:\tlearn: 3.3952820\ttest: 4.9154127\tbest: 4.9154127 (98)\ttotal: 10m 39s\tremaining: 5m 29s\n",
      "99:\tlearn: 3.3711695\ttest: 4.9062719\tbest: 4.9062719 (99)\ttotal: 10m 45s\tremaining: 5m 22s\n",
      "100:\tlearn: 3.3411711\ttest: 4.9047420\tbest: 4.9047420 (100)\ttotal: 10m 52s\tremaining: 5m 16s\n",
      "101:\tlearn: 3.3386179\ttest: 4.9044531\tbest: 4.9044531 (101)\ttotal: 10m 58s\tremaining: 5m 9s\n",
      "102:\tlearn: 3.3060675\ttest: 4.8989980\tbest: 4.8989980 (102)\ttotal: 11m 4s\tremaining: 5m 3s\n",
      "103:\tlearn: 3.2871404\ttest: 4.9009366\tbest: 4.8989980 (102)\ttotal: 11m 11s\tremaining: 4m 56s\n",
      "104:\tlearn: 3.2632110\ttest: 4.8903139\tbest: 4.8903139 (104)\ttotal: 11m 17s\tremaining: 4m 50s\n",
      "105:\tlearn: 3.2292442\ttest: 4.8742431\tbest: 4.8742431 (105)\ttotal: 11m 23s\tremaining: 4m 43s\n",
      "106:\tlearn: 3.2267675\ttest: 4.8741257\tbest: 4.8741257 (106)\ttotal: 11m 29s\tremaining: 4m 37s\n",
      "107:\tlearn: 3.2069065\ttest: 4.8757318\tbest: 4.8741257 (106)\ttotal: 11m 36s\tremaining: 4m 30s\n",
      "108:\tlearn: 3.2055642\ttest: 4.8751826\tbest: 4.8741257 (106)\ttotal: 11m 42s\tremaining: 4m 24s\n",
      "109:\tlearn: 3.1714791\ttest: 4.8673250\tbest: 4.8673250 (109)\ttotal: 11m 48s\tremaining: 4m 17s\n",
      "110:\tlearn: 3.1348750\ttest: 4.8574431\tbest: 4.8574431 (110)\ttotal: 11m 55s\tremaining: 4m 11s\n",
      "111:\tlearn: 3.1181733\ttest: 4.8579699\tbest: 4.8574431 (110)\ttotal: 12m 1s\tremaining: 4m 4s\n",
      "112:\tlearn: 3.1172546\ttest: 4.8572269\tbest: 4.8572269 (112)\ttotal: 12m 7s\tremaining: 3m 58s\n",
      "113:\tlearn: 3.1085223\ttest: 4.8575612\tbest: 4.8572269 (112)\ttotal: 12m 14s\tremaining: 3m 51s\n",
      "114:\tlearn: 3.0919191\ttest: 4.8486135\tbest: 4.8486135 (114)\ttotal: 12m 20s\tremaining: 3m 45s\n",
      "115:\tlearn: 3.0582812\ttest: 4.8506401\tbest: 4.8486135 (114)\ttotal: 12m 26s\tremaining: 3m 38s\n",
      "116:\tlearn: 3.0316566\ttest: 4.8323746\tbest: 4.8323746 (116)\ttotal: 12m 33s\tremaining: 3m 32s\n",
      "117:\tlearn: 3.0291610\ttest: 4.8321707\tbest: 4.8321707 (117)\ttotal: 12m 40s\tremaining: 3m 26s\n",
      "118:\tlearn: 3.0190855\ttest: 4.8311845\tbest: 4.8311845 (118)\ttotal: 12m 46s\tremaining: 3m 19s\n",
      "119:\tlearn: 2.9979551\ttest: 4.8333454\tbest: 4.8311845 (118)\ttotal: 12m 52s\tremaining: 3m 13s\n",
      "120:\tlearn: 2.9603154\ttest: 4.8318790\tbest: 4.8311845 (118)\ttotal: 12m 58s\tremaining: 3m 6s\n",
      "121:\tlearn: 2.9384553\ttest: 4.8351261\tbest: 4.8311845 (118)\ttotal: 13m 5s\tremaining: 3m\n",
      "122:\tlearn: 2.9008332\ttest: 4.8271771\tbest: 4.8271771 (122)\ttotal: 13m 11s\tremaining: 2m 53s\n",
      "123:\tlearn: 2.8904736\ttest: 4.8279957\tbest: 4.8271771 (122)\ttotal: 13m 17s\tremaining: 2m 47s\n",
      "124:\tlearn: 2.8674285\ttest: 4.8273312\tbest: 4.8271771 (122)\ttotal: 13m 24s\tremaining: 2m 40s\n",
      "125:\tlearn: 2.8499685\ttest: 4.8275304\tbest: 4.8271771 (122)\ttotal: 13m 30s\tremaining: 2m 34s\n",
      "126:\tlearn: 2.8392794\ttest: 4.8287564\tbest: 4.8271771 (122)\ttotal: 13m 37s\tremaining: 2m 28s\n",
      "127:\tlearn: 2.8169263\ttest: 4.8322105\tbest: 4.8271771 (122)\ttotal: 13m 43s\tremaining: 2m 21s\n",
      "128:\tlearn: 2.7989344\ttest: 4.8348517\tbest: 4.8271771 (122)\ttotal: 13m 50s\tremaining: 2m 15s\n",
      "129:\tlearn: 2.7843511\ttest: 4.8353443\tbest: 4.8271771 (122)\ttotal: 13m 56s\tremaining: 2m 8s\n",
      "130:\tlearn: 2.7687186\ttest: 4.8373383\tbest: 4.8271771 (122)\ttotal: 14m 3s\tremaining: 2m 2s\n",
      "131:\tlearn: 2.7440521\ttest: 4.8301008\tbest: 4.8271771 (122)\ttotal: 14m 9s\tremaining: 1m 55s\n",
      "132:\tlearn: 2.7394911\ttest: 4.8301523\tbest: 4.8271771 (122)\ttotal: 14m 16s\tremaining: 1m 49s\n",
      "133:\tlearn: 2.7153494\ttest: 4.8293445\tbest: 4.8271771 (122)\ttotal: 14m 22s\tremaining: 1m 43s\n",
      "134:\tlearn: 2.7088056\ttest: 4.8290107\tbest: 4.8271771 (122)\ttotal: 14m 29s\tremaining: 1m 36s\n",
      "135:\tlearn: 2.7053873\ttest: 4.8292512\tbest: 4.8271771 (122)\ttotal: 14m 35s\tremaining: 1m 30s\n",
      "136:\tlearn: 2.6698658\ttest: 4.8243457\tbest: 4.8243457 (136)\ttotal: 14m 42s\tremaining: 1m 23s\n",
      "137:\tlearn: 2.6576236\ttest: 4.8249087\tbest: 4.8243457 (136)\ttotal: 14m 48s\tremaining: 1m 17s\n",
      "138:\tlearn: 2.6296339\ttest: 4.8301065\tbest: 4.8243457 (136)\ttotal: 14m 55s\tremaining: 1m 10s\n",
      "139:\tlearn: 2.6192917\ttest: 4.8278621\tbest: 4.8243457 (136)\ttotal: 15m 1s\tremaining: 1m 4s\n",
      "140:\tlearn: 2.6082783\ttest: 4.8284759\tbest: 4.8243457 (136)\ttotal: 15m 7s\tremaining: 57.9s\n",
      "141:\tlearn: 2.5860777\ttest: 4.8296426\tbest: 4.8243457 (136)\ttotal: 15m 14s\tremaining: 51.5s\n",
      "142:\tlearn: 2.5820047\ttest: 4.8297678\tbest: 4.8243457 (136)\ttotal: 15m 20s\tremaining: 45.1s\n",
      "143:\tlearn: 2.5559939\ttest: 4.8285098\tbest: 4.8243457 (136)\ttotal: 15m 26s\tremaining: 38.6s\n",
      "144:\tlearn: 2.5410838\ttest: 4.8295027\tbest: 4.8243457 (136)\ttotal: 15m 33s\tremaining: 32.2s\n",
      "145:\tlearn: 2.5252482\ttest: 4.8316138\tbest: 4.8243457 (136)\ttotal: 15m 39s\tremaining: 25.7s\n",
      "146:\tlearn: 2.4922378\ttest: 4.8234842\tbest: 4.8234842 (146)\ttotal: 15m 46s\tremaining: 19.3s\n",
      "147:\tlearn: 2.4588556\ttest: 4.8187108\tbest: 4.8187108 (147)\ttotal: 15m 52s\tremaining: 12.9s\n",
      "148:\tlearn: 2.4441610\ttest: 4.8112033\tbest: 4.8112033 (148)\ttotal: 15m 58s\tremaining: 6.43s\n",
      "149:\tlearn: 2.4389888\ttest: 4.8054915\tbest: 4.8054915 (149)\ttotal: 16m 5s\tremaining: 0us\n",
      "\n",
      "bestTest = 4.805491473\n",
      "bestIteration = 149\n",
      "\n",
      "Model 2 is fitted: True\n",
      "Model 2 params:\n",
      "{'iterations': 150, 'depth': 3, 'loss_function': 'MultiClass', 'random_seed': 63, 'use_best_model': True}\n"
     ]
    }
   ],
   "source": [
    "model2 = CatBoostClassifier(\n",
    "    random_seed=63,\n",
    "    iterations=150,\n",
    "    # learning_rate=0.25,\n",
    "    depth=3,\n",
    "    loss_function='MultiClass',\n",
    "    use_best_model=True\n",
    ")\n",
    "\n",
    "model2.fit(\n",
    "    X_train, y_train,\n",
    "    cat_features=cat_features,\n",
    "    eval_set=(X_validation, y_validation),\n",
    "    init_model=model\n",
    "    # verbose=False\n",
    ")\n",
    "\n",
    "print('Model 2 is fitted: ' + str(model2.is_fitted()))\n",
    "print('Model 2 params:')\n",
    "print(model2.get_params())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.00315492 0.00318327 0.00318327 ... 0.00318327 0.0031294  0.00310324]\n",
      " [0.00315492 0.00318327 0.00318327 ... 0.00318327 0.0031294  0.00310324]\n",
      " [0.00315492 0.00318327 0.00318327 ... 0.00318327 0.0031294  0.00310324]\n",
      " ...\n",
      " [0.00315492 0.00318327 0.00318327 ... 0.00318327 0.0031294  0.00310324]\n",
      " [0.00314886 0.00312168 0.00312168 ... 0.00312168 0.00312339 0.00312365]\n",
      " [0.00315492 0.00318327 0.00318327 ... 0.00318327 0.0031294  0.00310324]]\n"
     ]
    }
   ],
   "source": [
    "print(model.predict_proba(X_validation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1157]\n",
      " [1157]\n",
      " [1157]\n",
      " [1157]\n",
      " [  34]\n",
      " [1074]\n",
      " [1157]\n",
      " [  34]\n",
      " [1074]\n",
      " [4512]\n",
      " [1157]\n",
      " [  12]\n",
      " [  13]\n",
      " [1470]\n",
      " [  34]\n",
      " [  16]\n",
      " [1074]\n",
      " [1279]\n",
      " [  12]\n",
      " [  34]\n",
      " [  34]\n",
      " [  12]\n",
      " [  34]\n",
      " [  34]\n",
      " [4512]\n",
      " [  34]\n",
      " [6064]\n",
      " [1279]\n",
      " [1074]\n",
      " [  34]\n",
      " [  31]\n",
      " [1800]\n",
      " [4307]\n",
      " [  34]\n",
      " [1157]\n",
      " [6065]\n",
      " [1470]\n",
      " [1526]\n",
      " [  39]\n",
      " [  34]\n",
      " [1157]\n",
      " [6065]\n",
      " [  13]\n",
      " [1526]\n",
      " [1074]\n",
      " [1074]\n",
      " [6065]\n",
      " [1279]\n",
      " [  34]\n",
      " [  34]\n",
      " [1074]\n",
      " [  34]\n",
      " [1157]\n",
      " [  34]\n",
      " [1470]\n",
      " [4512]\n",
      " [1183]\n",
      " [1470]\n",
      " [6065]\n",
      " [1800]\n",
      " [1074]\n",
      " [6065]\n",
      " [6065]\n",
      " [6065]\n",
      " [1800]\n",
      " [1279]\n",
      " [1470]\n",
      " [1144]\n",
      " [1036]\n",
      " [1074]\n",
      " [1800]\n",
      " [1470]\n",
      " [6065]\n",
      " [1800]\n",
      " [1401]\n",
      " [4512]\n",
      " [1066]\n",
      " [  34]\n",
      " [6065]\n",
      " [6065]\n",
      " [  34]\n",
      " [1074]\n",
      " [  34]\n",
      " [  34]\n",
      " [1157]\n",
      " [1800]\n",
      " [1279]\n",
      " [1401]\n",
      " [1800]\n",
      " [1800]\n",
      " [1401]\n",
      " [1144]\n",
      " [1800]\n",
      " [3507]\n",
      " [4307]\n",
      " [  34]\n",
      " [3631]\n",
      " [  34]\n",
      " [  34]\n",
      " [1761]\n",
      " [  34]\n",
      " [1800]\n",
      " [3592]\n",
      " [1144]\n",
      " [1640]\n",
      " [1157]\n",
      " [1800]\n",
      " [3631]\n",
      " [1144]\n",
      " [4512]\n",
      " [1800]\n",
      " [1800]\n",
      " [  34]\n",
      " [1183]\n",
      " [3524]\n",
      " [1401]\n",
      " [  34]\n",
      " [1470]\n",
      " [1401]\n",
      " [1470]\n",
      " [1279]\n",
      " [1215]\n",
      " [6065]\n",
      " [1800]\n",
      " [6064]\n",
      " [6019]\n",
      " [1279]\n",
      " [1144]\n",
      " [1800]\n",
      " [3914]\n",
      " [3507]\n",
      " [4229]\n",
      " [4229]\n",
      " [1279]\n",
      " [1036]\n",
      " [6065]\n",
      " [1821]\n",
      " [1183]\n",
      " [  39]\n",
      " [4512]\n",
      " [  34]\n",
      " [1238]\n",
      " [6065]\n",
      " [1279]\n",
      " [3631]\n",
      " [  34]\n",
      " [  34]\n",
      " [1036]\n",
      " [6065]\n",
      " [1401]\n",
      " [1800]\n",
      " [1640]\n",
      " [4307]\n",
      " [1074]\n",
      " [1640]\n",
      " [3524]\n",
      " [4307]\n",
      " [6065]\n",
      " [1470]\n",
      " [4512]\n",
      " [1144]\n",
      " [4229]\n",
      " [1401]\n",
      " [3914]\n",
      " [  34]\n",
      " [1800]\n",
      " [6065]\n",
      " [1470]\n",
      " [1401]\n",
      " [  34]\n",
      " [4307]\n",
      " [6065]\n",
      " [1800]\n",
      " [6065]\n",
      " [1279]\n",
      " [1279]\n",
      " [1066]\n",
      " [4307]\n",
      " [6065]\n",
      " [1144]\n",
      " [1401]\n",
      " [6065]\n",
      " [1801]\n",
      " [  34]\n",
      " [6065]\n",
      " [1800]\n",
      " [1821]\n",
      " [3631]\n",
      " [6019]\n",
      " [1157]\n",
      " [1183]\n",
      " [6065]\n",
      " [  16]\n",
      " [6065]\n",
      " [1468]\n",
      " [1144]\n",
      " [  34]\n",
      " [1036]\n",
      " [1470]\n",
      " [  34]\n",
      " [1640]\n",
      " [3631]\n",
      " [  34]\n",
      " [1074]\n",
      " [1761]\n",
      " [6064]\n",
      " [1144]\n",
      " [3914]\n",
      " [1183]\n",
      " [4229]\n",
      " [  34]\n",
      " [4512]\n",
      " [4307]\n",
      " [6066]\n",
      " [1401]\n",
      " [1800]\n",
      " [6040]\n",
      " [4512]\n",
      " [1526]\n",
      " [  34]\n",
      " [1215]\n",
      " [3631]\n",
      " [  34]\n",
      " [1509]\n",
      " [1157]\n",
      " [1157]\n",
      " [  34]\n",
      " [  34]\n",
      " [4512]\n",
      " [6065]\n",
      " [1401]\n",
      " [1401]\n",
      " [1526]\n",
      " [1401]\n",
      " [1279]\n",
      " [6065]\n",
      " [1401]\n",
      " [1074]\n",
      " [1401]\n",
      " [1800]\n",
      " [1800]\n",
      " [1800]\n",
      " [1144]\n",
      " [1546]\n",
      " [1401]\n",
      " [  34]\n",
      " [4229]\n",
      " [6019]\n",
      " [  34]\n",
      " [6064]\n",
      " [1800]\n",
      " [1640]\n",
      " [1800]\n",
      " [6065]\n",
      " [6065]\n",
      " [1144]\n",
      " [6066]\n",
      " [1279]\n",
      " [4229]\n",
      " [1800]\n",
      " [1800]\n",
      " [6065]\n",
      " [6065]\n",
      " [1640]\n",
      " [1800]\n",
      " [  34]\n",
      " [6066]\n",
      " [4512]\n",
      " [  34]\n",
      " [1640]\n",
      " [  34]\n",
      " [4243]\n",
      " [3524]\n",
      " [  39]\n",
      " [3524]\n",
      " [6075]\n",
      " [  34]\n",
      " [1401]\n",
      " [  34]\n",
      " [1144]\n",
      " [  34]\n",
      " [1800]\n",
      " [3524]\n",
      " [1470]\n",
      " [1470]\n",
      " [  34]\n",
      " [1470]\n",
      " [1401]\n",
      " [1800]\n",
      " [1800]\n",
      " [1470]\n",
      " [  34]\n",
      " [1470]\n",
      " [1761]\n",
      " [1144]\n",
      " [6065]\n",
      " [1800]\n",
      " [1526]\n",
      " [1470]\n",
      " [1800]\n",
      " [1801]\n",
      " [4307]\n",
      " [1821]\n",
      " [6065]\n",
      " [6065]\n",
      " [1761]\n",
      " [1144]\n",
      " [1800]\n",
      " [  34]\n",
      " [3507]\n",
      " [3914]\n",
      " [1821]\n",
      " [1036]\n",
      " [1183]\n",
      " [1526]\n",
      " [1800]\n",
      " [1546]\n",
      " [1470]\n",
      " [1821]\n",
      " [1470]]\n"
     ]
    }
   ],
   "source": [
    "print(model.predict(X_validation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature Id</th>\n",
       "      <th>Importances</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Largo de pelaje</td>\n",
       "      <td>37.479364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Color de ojos</td>\n",
       "      <td>16.002910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Color de pelaje 3</td>\n",
       "      <td>14.736305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tama√±o</td>\n",
       "      <td>14.159547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Color de pelaje 1</td>\n",
       "      <td>11.721368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Largo de hocico</td>\n",
       "      <td>4.931495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Edad</td>\n",
       "      <td>0.969011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Sexo</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Patron de pelaje</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Color de pelaje 2</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Largo de cola</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Largo de orejas</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Tipo de orejas</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Feature Id  Importances\n",
       "0     Largo de pelaje    37.479364\n",
       "1       Color de ojos    16.002910\n",
       "2   Color de pelaje 3    14.736305\n",
       "3              Tama√±o    14.159547\n",
       "4   Color de pelaje 1    11.721368\n",
       "5     Largo de hocico     4.931495\n",
       "6                Edad     0.969011\n",
       "7                Sexo     0.000000\n",
       "8    Patron de pelaje     0.000000\n",
       "9   Color de pelaje 2     0.000000\n",
       "10      Largo de cola     0.000000\n",
       "11    Largo de orejas     0.000000\n",
       "12     Tipo de orejas     0.000000"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction1 = model.get_feature_importance(prettified=True)\n",
    "prediction1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature Id</th>\n",
       "      <th>Importances</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Largo de pelaje</td>\n",
       "      <td>31.113495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Color de ojos</td>\n",
       "      <td>19.111838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Color de pelaje 3</td>\n",
       "      <td>18.343051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tama√±o</td>\n",
       "      <td>15.203147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Color de pelaje 1</td>\n",
       "      <td>13.274599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Largo de hocico</td>\n",
       "      <td>2.468770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Edad</td>\n",
       "      <td>0.485100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Sexo</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Patron de pelaje</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Color de pelaje 2</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Largo de cola</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Largo de orejas</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Tipo de orejas</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Feature Id  Importances\n",
       "0     Largo de pelaje    31.113495\n",
       "1       Color de ojos    19.111838\n",
       "2   Color de pelaje 3    18.343051\n",
       "3              Tama√±o    15.203147\n",
       "4   Color de pelaje 1    13.274599\n",
       "5     Largo de hocico     2.468770\n",
       "6                Edad     0.485100\n",
       "7                Sexo     0.000000\n",
       "8    Patron de pelaje     0.000000\n",
       "9   Color de pelaje 2     0.000000\n",
       "10      Largo de cola     0.000000\n",
       "11    Largo de orejas     0.000000\n",
       "12     Tipo de orejas     0.000000"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction2 = model2.get_feature_importance(prettified=True)\n",
    "prediction2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature Id</th>\n",
       "      <th>Importances</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Largo de pelaje</td>\n",
       "      <td>31.113495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Color de ojos</td>\n",
       "      <td>19.111838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Color de pelaje 3</td>\n",
       "      <td>18.343051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tama√±o</td>\n",
       "      <td>15.203147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Color de pelaje 1</td>\n",
       "      <td>13.274599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Largo de hocico</td>\n",
       "      <td>2.468770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Edad</td>\n",
       "      <td>0.485100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Sexo</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Patron de pelaje</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Color de pelaje 2</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Largo de cola</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Largo de orejas</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Tipo de orejas</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Feature Id  Importances\n",
       "0     Largo de pelaje    31.113495\n",
       "1       Color de ojos    19.111838\n",
       "2   Color de pelaje 3    18.343051\n",
       "3              Tama√±o    15.203147\n",
       "4   Color de pelaje 1    13.274599\n",
       "5     Largo de hocico     2.468770\n",
       "6                Edad     0.485100\n",
       "7                Sexo     0.000000\n",
       "8    Patron de pelaje     0.000000\n",
       "9   Color de pelaje 2     0.000000\n",
       "10      Largo de cola     0.000000\n",
       "11    Largo de orejas     0.000000\n",
       "12     Tipo de orejas     0.000000"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction3 = model2.get_feature_importance(prettified=True)\n",
    "prediction3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y = train_df.Mascota\n",
    "test_df = train_df.drop('Mascota', axis=1)\n",
    "\n",
    "test_df.fillna(\"NaN\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1401]\n",
      " [1157]\n",
      " [  13]\n",
      " [1157]\n",
      " [   5]\n",
      " [1074]\n",
      " [1401]\n",
      " [  34]\n",
      " [1074]\n",
      " [3914]\n",
      " [1157]\n",
      " [6040]\n",
      " [  13]\n",
      " [  13]\n",
      " [  34]\n",
      " [  16]\n",
      " [1074]\n",
      " [1279]\n",
      " [6040]\n",
      " [3507]\n",
      " [3507]\n",
      " [6040]\n",
      " [  34]\n",
      " [  34]\n",
      " [4512]\n",
      " [  34]\n",
      " [1526]\n",
      " [1279]\n",
      " [6066]\n",
      " [  34]\n",
      " [  38]\n",
      " [1800]\n",
      " [  16]\n",
      " [  34]\n",
      " [1157]\n",
      " [6065]\n",
      " [  13]\n",
      " [1526]\n",
      " [  39]\n",
      " [  34]\n",
      " [1157]\n",
      " [4512]\n",
      " [  13]\n",
      " [1526]\n",
      " [1074]\n",
      " [1074]\n",
      " [4512]\n",
      " [1279]\n",
      " [3507]\n",
      " [  34]\n",
      " [1074]\n",
      " [4243]\n",
      " [1157]\n",
      " [4537]\n",
      " [1401]\n",
      " [4512]\n",
      " [1183]\n",
      " [  13]\n",
      " [6065]\n",
      " [1800]\n",
      " [1074]\n",
      " [4512]\n",
      " [4512]\n",
      " [6065]\n",
      " [1800]\n",
      " [1279]\n",
      " [1401]\n",
      " [3507]\n",
      " [1036]\n",
      " [1074]\n",
      " [6066]\n",
      " [1401]\n",
      " [6065]\n",
      " [1800]\n",
      " [1401]\n",
      " [4512]\n",
      " [1066]\n",
      " [4537]\n",
      " [4512]\n",
      " [4512]\n",
      " [  34]\n",
      " [1074]\n",
      " [  34]\n",
      " [  34]\n",
      " [1157]\n",
      " [6072]\n",
      " [1279]\n",
      " [1401]\n",
      " [3507]\n",
      " [3507]\n",
      " [1401]\n",
      " [6066]\n",
      " [6066]\n",
      " [3507]\n",
      " [3524]\n",
      " [  34]\n",
      " [3524]\n",
      " [  34]\n",
      " [  34]\n",
      " [6040]\n",
      " [  34]\n",
      " [3507]\n",
      " [3592]\n",
      " [6066]\n",
      " [3595]\n",
      " [1157]\n",
      " [6066]\n",
      " [3524]\n",
      " [3507]\n",
      " [4512]\n",
      " [1800]\n",
      " [4243]\n",
      " [4537]\n",
      " [1183]\n",
      " [1486]\n",
      " [1401]\n",
      " [  34]\n",
      " [1470]\n",
      " [1401]\n",
      " [1470]\n",
      " [1279]\n",
      " [1215]\n",
      " [3914]\n",
      " [1800]\n",
      " [1217]\n",
      " [6019]\n",
      " [1279]\n",
      " [3507]\n",
      " [6066]\n",
      " [3914]\n",
      " [3507]\n",
      " [1279]\n",
      " [1279]\n",
      " [1279]\n",
      " [1902]\n",
      " [4512]\n",
      " [  16]\n",
      " [1183]\n",
      " [1652]\n",
      " [4512]\n",
      " [  34]\n",
      " [1238]\n",
      " [4512]\n",
      " [1279]\n",
      " [1509]\n",
      " [4537]\n",
      " [  34]\n",
      " [1279]\n",
      " [4512]\n",
      " [1401]\n",
      " [1800]\n",
      " [1640]\n",
      " [3524]\n",
      " [1074]\n",
      " [1640]\n",
      " [1509]\n",
      " [  16]\n",
      " [4512]\n",
      " [1401]\n",
      " [3914]\n",
      " [6066]\n",
      " [4229]\n",
      " [1401]\n",
      " [3914]\n",
      " [4537]\n",
      " [3507]\n",
      " [4512]\n",
      " [  13]\n",
      " [1401]\n",
      " [4537]\n",
      " [3524]\n",
      " [4512]\n",
      " [1800]\n",
      " [6065]\n",
      " [1279]\n",
      " [1279]\n",
      " [1066]\n",
      " [3524]\n",
      " [6065]\n",
      " [3507]\n",
      " [1401]\n",
      " [6065]\n",
      " [6017]\n",
      " [4537]\n",
      " [6065]\n",
      " [6066]\n",
      " [  16]\n",
      " [3524]\n",
      " [6019]\n",
      " [1401]\n",
      " [1183]\n",
      " [1036]\n",
      " [  16]\n",
      " [6065]\n",
      " [1468]\n",
      " [3507]\n",
      " [4537]\n",
      " [1036]\n",
      " [1470]\n",
      " [  34]\n",
      " [1640]\n",
      " [3524]\n",
      " [   5]\n",
      " [1074]\n",
      " [6040]\n",
      " [1217]\n",
      " [6066]\n",
      " [3914]\n",
      " [1486]\n",
      " [1279]\n",
      " [3507]\n",
      " [4512]\n",
      " [  16]\n",
      " [6066]\n",
      " [1401]\n",
      " [4243]\n",
      " [6040]\n",
      " [4512]\n",
      " [1526]\n",
      " [3507]\n",
      " [1215]\n",
      " [1509]\n",
      " [   5]\n",
      " [1509]\n",
      " [1157]\n",
      " [1401]\n",
      " [4537]\n",
      " [4537]\n",
      " [3914]\n",
      " [3914]\n",
      " [1401]\n",
      " [1401]\n",
      " [1526]\n",
      " [1401]\n",
      " [1279]\n",
      " [4512]\n",
      " [1401]\n",
      " [1074]\n",
      " [1401]\n",
      " [3507]\n",
      " [6066]\n",
      " [6066]\n",
      " [3507]\n",
      " [1546]\n",
      " [1401]\n",
      " [4243]\n",
      " [4229]\n",
      " [6019]\n",
      " [4537]\n",
      " [1526]\n",
      " [6066]\n",
      " [1640]\n",
      " [6066]\n",
      " [6065]\n",
      " [4512]\n",
      " [3507]\n",
      " [6066]\n",
      " [1279]\n",
      " [1279]\n",
      " [6066]\n",
      " [6066]\n",
      " [4512]\n",
      " [1596]\n",
      " [1640]\n",
      " [1800]\n",
      " [4537]\n",
      " [1800]\n",
      " [4512]\n",
      " [  34]\n",
      " [1640]\n",
      " [4537]\n",
      " [4243]\n",
      " [3524]\n",
      " [1549]\n",
      " [3524]\n",
      " [4537]\n",
      " [4537]\n",
      " [1401]\n",
      " [4537]\n",
      " [6066]\n",
      " [4537]\n",
      " [6066]\n",
      " [3524]\n",
      " [1470]\n",
      " [  13]\n",
      " [1074]\n",
      " [1470]\n",
      " [1401]\n",
      " [1800]\n",
      " [4243]\n",
      " [1470]\n",
      " [1074]\n",
      " [1470]\n",
      " [6040]\n",
      " [3507]\n",
      " [4512]\n",
      " [6066]\n",
      " [1526]\n",
      " [1401]\n",
      " [1800]\n",
      " [1801]\n",
      " [3524]\n",
      " [1821]\n",
      " [4512]\n",
      " [6065]\n",
      " [6040]\n",
      " [6066]\n",
      " [1800]\n",
      " [4537]\n",
      " [3507]\n",
      " [3914]\n",
      " [  16]\n",
      " [1036]\n",
      " [1183]\n",
      " [1526]\n",
      " [3507]\n",
      " [1546]\n",
      " [  13]\n",
      " [  16]\n",
      " [1470]]\n"
     ]
    }
   ],
   "source": [
    "# print(model.predict_proba(test_df))\n",
    "print(model2.predict(test_df))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
